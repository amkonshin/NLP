{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "HW3.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "BbSDHS0_0jhQ"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjMB4vid0jhU"
      },
      "source": [
        "df=pd.read_csv('tweets.csv', index_col=0)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e4Ll5ANo0jhY",
        "outputId": "a5b5997f-cd39-4bdd-c49b-ab7e178e97c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 603
        }
      },
      "source": [
        "df"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "      <th>clear_tweet</th>\n",
              "      <th>tweet_token</th>\n",
              "      <th>tweet_token_filtered</th>\n",
              "      <th>tweet_stemmed</th>\n",
              "      <th>tweet_lemmatized</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>@user when a father is dysfunctional and is s...</td>\n",
              "      <td>when father is dysfunctional and is so selfish...</td>\n",
              "      <td>['when', 'father', 'is', 'dysfunctional', 'and...</td>\n",
              "      <td>['father', 'dysfunctional', 'selfish', 'drags'...</td>\n",
              "      <td>['father', 'dysfunct', 'selfish', 'drag', 'kid...</td>\n",
              "      <td>['father', 'dysfunctional', 'selfish', 'drag',...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
              "      <td>thanks for lyft credit cannot use because they...</td>\n",
              "      <td>['thanks', 'for', 'lyft', 'credit', 'can', 'no...</td>\n",
              "      <td>['thanks', 'lyft', 'credit', 'use', 'offer', '...</td>\n",
              "      <td>['thank', 'lyft', 'credit', 'use', 'offer', 'w...</td>\n",
              "      <td>['thank', 'lyft', 'credit', 'use', 'offer', 'w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>bihday your majesty</td>\n",
              "      <td>bihday your majesty</td>\n",
              "      <td>['bihday', 'your', 'majesty']</td>\n",
              "      <td>['bihday', 'majesty']</td>\n",
              "      <td>['bihday', 'majesti']</td>\n",
              "      <td>['bihday', 'majesty']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>#model   i love u take with u all the time in ...</td>\n",
              "      <td>model love you take with you all the time in your</td>\n",
              "      <td>['model', 'love', 'you', 'take', 'with', 'you'...</td>\n",
              "      <td>['model', 'love', 'take', 'time']</td>\n",
              "      <td>['model', 'love', 'take', 'time']</td>\n",
              "      <td>['model', 'love', 'take', 'time']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.0</td>\n",
              "      <td>factsguide: society now    #motivation</td>\n",
              "      <td>factsguide society now motivation</td>\n",
              "      <td>['factsguide', 'society', 'now', 'motivation']</td>\n",
              "      <td>['factsguide', 'society', 'motivation']</td>\n",
              "      <td>['factsguid', 'societi', 'motiv']</td>\n",
              "      <td>['factsguide', 'society', 'motivation']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49155</th>\n",
              "      <td>NaN</td>\n",
              "      <td>thought factory: left-right polarisation! #tru...</td>\n",
              "      <td>thought factory left right polarisation trump ...</td>\n",
              "      <td>['thought', 'factory', 'left', 'right', 'polar...</td>\n",
              "      <td>['thought', 'factory', 'left', 'right', 'polar...</td>\n",
              "      <td>['thought', 'factori', 'left', 'right', 'polar...</td>\n",
              "      <td>['think', 'factory', 'leave', 'right', 'polari...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49156</th>\n",
              "      <td>NaN</td>\n",
              "      <td>feeling like a mermaid ð #hairflip #neverre...</td>\n",
              "      <td>feeling like mermaid hairflip neverready forma...</td>\n",
              "      <td>['feeling', 'like', 'mermaid', 'hairflip', 'ne...</td>\n",
              "      <td>['feeling', 'like', 'mermaid', 'hairflip', 'ne...</td>\n",
              "      <td>['feel', 'like', 'mermaid', 'hairflip', 'never...</td>\n",
              "      <td>['feel', 'like', 'mermaid', 'hairflip', 'never...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49157</th>\n",
              "      <td>NaN</td>\n",
              "      <td>#hillary #campaigned today in #ohio((omg)) &amp;am...</td>\n",
              "      <td>hillary campaigned today in ohio omg used word...</td>\n",
              "      <td>['hillary', 'campaigned', 'today', 'in', 'ohio...</td>\n",
              "      <td>['hillary', 'campaigned', 'today', 'ohio', 'om...</td>\n",
              "      <td>['hillari', 'campaign', 'today', 'ohio', 'omg'...</td>\n",
              "      <td>['hillary', 'campaign', 'today', 'ohio', 'omg'...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49158</th>\n",
              "      <td>NaN</td>\n",
              "      <td>happy, at work conference: right mindset leads...</td>\n",
              "      <td>happy at work conference right mindset leads t...</td>\n",
              "      <td>['happy', 'at', 'work', 'conference', 'right',...</td>\n",
              "      <td>['happy', 'work', 'conference', 'right', 'mind...</td>\n",
              "      <td>['happi', 'work', 'confer', 'right', 'mindset'...</td>\n",
              "      <td>['happy', 'work', 'conference', 'right', 'mind...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49159</th>\n",
              "      <td>NaN</td>\n",
              "      <td>my   song \"so glad\" free download!  #shoegaze ...</td>\n",
              "      <td>my song so glad free download shoegaze newmusi...</td>\n",
              "      <td>['my', 'song', 'so', 'glad', 'free', 'download...</td>\n",
              "      <td>['song', 'glad', 'free', 'download', 'shoegaze...</td>\n",
              "      <td>['song', 'glad', 'free', 'download', 'shoegaz'...</td>\n",
              "      <td>['song', 'glad', 'free', 'download', 'shoegaze...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>49159 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       label  ...                                   tweet_lemmatized\n",
              "id            ...                                                   \n",
              "1        0.0  ...  ['father', 'dysfunctional', 'selfish', 'drag',...\n",
              "2        0.0  ...  ['thank', 'lyft', 'credit', 'use', 'offer', 'w...\n",
              "3        0.0  ...                              ['bihday', 'majesty']\n",
              "4        0.0  ...                  ['model', 'love', 'take', 'time']\n",
              "5        0.0  ...            ['factsguide', 'society', 'motivation']\n",
              "...      ...  ...                                                ...\n",
              "49155    NaN  ...  ['think', 'factory', 'leave', 'right', 'polari...\n",
              "49156    NaN  ...  ['feel', 'like', 'mermaid', 'hairflip', 'never...\n",
              "49157    NaN  ...  ['hillary', 'campaign', 'today', 'ohio', 'omg'...\n",
              "49158    NaN  ...  ['happy', 'work', 'conference', 'right', 'mind...\n",
              "49159    NaN  ...  ['song', 'glad', 'free', 'download', 'shoegaze...\n",
              "\n",
              "[49159 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yAgVY3Lm0jhb"
      },
      "source": [
        "#!pip install -U spacy\n",
        "#!python -m spacy info"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5XbFw1TQ0jhf"
      },
      "source": [
        "import spacy"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kbaqpkoo1o75",
        "outputId": "416e7eab-9bfa-4832-f7b8-157ba91bcab4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        }
      },
      "source": [
        "!python -m spacy download en_core_web_md"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting en_core_web_md==2.2.5\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-2.2.5/en_core_web_md-2.2.5.tar.gz (96.4MB)\n",
            "\u001b[K     |████████████████████████████████| 96.4MB 1.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from en_core_web_md==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (0.8.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (2.0.3)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (3.0.2)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (50.3.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.18.5)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_md==2.2.5) (2.0.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_md==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_md==2.2.5) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_md==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_md==2.2.5) (2020.6.20)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_md==2.2.5) (3.2.0)\n",
            "Building wheels for collected packages: en-core-web-md\n",
            "  Building wheel for en-core-web-md (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for en-core-web-md: filename=en_core_web_md-2.2.5-cp36-none-any.whl size=98051305 sha256=393ce6abdd95733efc5ffa233d1b3838494e0e665c339cd90b32770706f39013\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-5ougpbvz/wheels/df/94/ad/f5cf59224cea6b5686ac4fd1ad19c8a07bc026e13c36502d81\n",
            "Successfully built en-core-web-md\n",
            "Installing collected packages: en-core-web-md\n",
            "Successfully installed en-core-web-md-2.2.5\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_md')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "az-OrSv60jhh"
      },
      "source": [
        "\n",
        "from spacy import displacy\n",
        "import en_core_web_md\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f8jnwBiB2ACO"
      },
      "source": [
        "nlp = en_core_web_md.load()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0k6l3eVcNtuc"
      },
      "source": [
        "result=pd.DataFrame(columns=['NER', 'Name', 'Count'])\n",
        "i=0\n",
        "for i,values in df['clear_tweet'].iteritems():\n",
        "  doc=nlp(str(values))\n",
        "  for ent in doc.ents:\n",
        "    result.loc[i,'NER']=ent.label_\n",
        "    result.loc[i,'Name']=ent.text\n",
        "    result.loc[i,'Count']=1\n",
        "    i+=1\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zrye3BrCORtW",
        "outputId": "1606a40f-1067-4a03-f994-ca59852a0760",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "result"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>NER</th>\n",
              "      <th>Name</th>\n",
              "      <th>Count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ORG</td>\n",
              "      <td>lyft credit</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ORG</td>\n",
              "      <td>bihday</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>ORG</td>\n",
              "      <td>factsguide society</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>DATE</td>\n",
              "      <td>tomorrow</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>DATE</td>\n",
              "      <td>the next school year</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49156</th>\n",
              "      <td>PERSON</td>\n",
              "      <td>mermaid hairflip neverready</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49157</th>\n",
              "      <td>PERSON</td>\n",
              "      <td>hillary</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49158</th>\n",
              "      <td>DATE</td>\n",
              "      <td>today</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49159</th>\n",
              "      <td>PERSON</td>\n",
              "      <td>newmusic newsong</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49160</th>\n",
              "      <td>PERSON</td>\n",
              "      <td>clinton</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>38375 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          NER                         Name Count\n",
              "2         ORG                  lyft credit     1\n",
              "3         ORG                       bihday     1\n",
              "5         ORG           factsguide society     1\n",
              "7        DATE                     tomorrow     1\n",
              "8        DATE         the next school year     1\n",
              "...       ...                          ...   ...\n",
              "49156  PERSON  mermaid hairflip neverready     1\n",
              "49157  PERSON                      hillary     1\n",
              "49158    DATE                        today     1\n",
              "49159  PERSON             newmusic newsong     1\n",
              "49160  PERSON                      clinton     1\n",
              "\n",
              "[38375 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqL4HuyFZuNj"
      },
      "source": [
        "top=result.loc[:,['NER','Count']].groupby('NER').sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYZunZFUaB7Z",
        "outputId": "b04c4aef-1e0d-4b69-ae8d-02d9c75cba1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 638
        }
      },
      "source": [
        "top.sort_values(by='Count', ascending =False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NER</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>PERSON</th>\n",
              "      <td>13616</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DATE</th>\n",
              "      <td>8224</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ORG</th>\n",
              "      <td>7193</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GPE</th>\n",
              "      <td>4046</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TIME</th>\n",
              "      <td>1725</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NORP</th>\n",
              "      <td>1388</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CARDINAL</th>\n",
              "      <td>909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ORDINAL</th>\n",
              "      <td>425</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FAC</th>\n",
              "      <td>251</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LOC</th>\n",
              "      <td>191</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PRODUCT</th>\n",
              "      <td>125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>WORK_OF_ART</th>\n",
              "      <td>125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>EVENT</th>\n",
              "      <td>83</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LANGUAGE</th>\n",
              "      <td>24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>QUANTITY</th>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LAW</th>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MONEY</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PERCENT</th>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             Count\n",
              "NER               \n",
              "PERSON       13616\n",
              "DATE          8224\n",
              "ORG           7193\n",
              "GPE           4046\n",
              "TIME          1725\n",
              "NORP          1388\n",
              "CARDINAL       909\n",
              "ORDINAL        425\n",
              "FAC            251\n",
              "LOC            191\n",
              "PRODUCT        125\n",
              "WORK_OF_ART    125\n",
              "EVENT           83\n",
              "LANGUAGE        24\n",
              "QUANTITY        20\n",
              "LAW             16\n",
              "MONEY           10\n",
              "PERCENT          4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YiU_P38fbGqz"
      },
      "source": [
        "person_spicy=result[result['NER']=='PERSON'].groupby('Name').sum().sort_values(by='Count', ascending =False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dA5JmRJbyVD",
        "outputId": "a51d47b3-fb21-473f-cbc0-29ff5008cc63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "person_spicy['Count'].head(20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Name\n",
              "bihday                                                     140\n",
              "bing bong bing bong                                        107\n",
              "lighttherapy                                                97\n",
              "obama                                                       83\n",
              "yoyou                                                       64\n",
              "hu                                                          50\n",
              "hillary                                                     43\n",
              "feminismiscancer feminismisterrorism feminismmuktbharat     40\n",
              "essentialoils                                               39\n",
              "staed                                                       36\n",
              "fathersday                                                  34\n",
              "sea shepherd suppoers                                       28\n",
              "brexit blm                                                  27\n",
              "christina grimmie                                           26\n",
              "shi                                                         26\n",
              "lebron                                                      24\n",
              "jesus                                                       24\n",
              "donald trump                                                23\n",
              "detoxdiet altwaystoheal                                     21\n",
              "jo cox                                                      19\n",
              "Name: Count, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S3-owNTQb97l"
      },
      "source": [
        "Спайси отработал скорее плохо, чем хорошо. Из топ 20 персон действительно людьми оказались лишь 6. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eYXxHOECb7z_"
      },
      "source": [
        "person_org=result[result['NER']=='ORG'].groupby('Name').sum().sort_values(by='Count', ascending =False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVh02OB2cbHX",
        "outputId": "08c16b4f-43b3-4fcc-d39e-224ae6651301",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "person_org['Count'].head(20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Name\n",
              "fathersday                 251\n",
              "bihday                     128\n",
              "allahsoil                  104\n",
              "sjw                        101\n",
              "gop                         48\n",
              "instagram                   40\n",
              "nba                         39\n",
              "google                      30\n",
              "stas                        27\n",
              "cavs                        27\n",
              "tgif ff                     26\n",
              "brexit                      25\n",
              "udtapunjab                  25\n",
              "gif                         25\n",
              "update social analytics     24\n",
              "disney                      23\n",
              "islam                       22\n",
              "unfounately                 22\n",
              "impoant                     21\n",
              "eur usd                     19\n",
              "Name: Count, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MIgJ1ItWclGG"
      },
      "source": [
        "Тоже касается и организаций. Из ТОП-20 лишь 5-6 являются организациями, много мусора."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p12Wm8X54X8U"
      },
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tag import pos_tag"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "We2B-qrg6VtD"
      },
      "source": [
        ""
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ij9C0Wc16fpd",
        "outputId": "84a473b8-0fc0-43f2-8e6f-0187fc87c0a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "nltk.download('punkt')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AlQ0k79y6jYM",
        "outputId": "e20c20f4-8fe0-49c3-8487-c797389b4666",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "nltk.download('words')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPHfPXYo6cdI",
        "outputId": "15727716-a90b-4b35-a8c1-11f3ad919c00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "i=0\n",
        "for sent in nltk.sent_tokenize(sentence):\n",
        "  ne_tree = nltk.ne_chunk(pos_tag(word_tokenize(sent)))\n",
        "  named_entities = []\n",
        "  for tagged_tree in ne_tree:\n",
        "    print(tagged_tree)\n",
        "    if hasattr(tagged_tree, 'label'):\n",
        "      entity_name = ' '.join(c[0] for c in tagged_tree.leaves()) #\n",
        "      entity_type = tagged_tree.label() # get NE category\n",
        "      nltk_df.loc[i,'NER']=entity_type\n",
        "      nltk_df.loc[i,'Name']=entity_name\n",
        "      named_entities.append((entity_name, entity_type))\n",
        "      i+=1\n",
        "  print(named_entities)\n",
        "  #print(cs)\n",
        "  #print(sent)  "
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('thought', 'JJ')\n",
            "('factory', 'NN')\n",
            "('left', 'VBD')\n",
            "('right', 'JJ')\n",
            "('polarisation', 'NN')\n",
            "('trump', 'NN')\n",
            "(PERSON Donald/NNP)\n",
            "('google', 'NN')\n",
            "(PERSON Google/NNP)\n",
            "('.', '.')\n",
            "[('Donald', 'PERSON'), ('Google', 'PERSON')]\n",
            "('i', 'NN')\n",
            "('want', 'VBP')\n",
            "('bmw', 'NN')\n",
            "[]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9hWHXD_tRYHF"
      },
      "source": [
        "nltk_df=pd.DataFrame(columns=['NER', 'Name', 'Count'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_MlGKUWHABxh"
      },
      "source": [
        "i=0\n",
        "for j, sentence in df['tweet'].iteritems():\n",
        "  for sent in nltk.sent_tokenize(str(sentence)):\n",
        "    for chunk in nltk.ne_chunk(nltk.pos_tag(nltk.word_tokenize(sent))):\n",
        "        if hasattr(chunk, 'label'):\n",
        "          #print(chunk.label(), ' '.join(c[0] for c in chunk))\n",
        "          nltk_df.loc[i,'NER']=chunk.label()\n",
        "          nltk_df.loc[i,'Name']=' '.join(c[0] for c in chunk)\n",
        "          nltk_df.loc[i,'Count']=1\n",
        "          i+=1\n",
        "              "
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6jWcQWLvR7ZH",
        "outputId": "1046521c-5fe8-4e91-9d8a-d2263348bbf0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "nltk_df"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>NER</th>\n",
              "      <th>Name</th>\n",
              "      <th>Count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>GPE</td>\n",
              "      <td>en-ger-land</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>GPE</td>\n",
              "      <td>en-ger-land</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>GPE</td>\n",
              "      <td>brisk_and_vagabond-eyeopener_2007__enviromenta...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>GPE</td>\n",
              "      <td>u.s.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ORGANIZATION</td>\n",
              "      <td>nycÂ</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>111</th>\n",
              "      <td>ORGANIZATION</td>\n",
              "      <td>vysoÄina</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>112</th>\n",
              "      <td>ORGANIZATION</td>\n",
              "      <td>euro2016Â</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>113</th>\n",
              "      <td>GPE</td>\n",
              "      <td>brisk_and_ham-taste_the_rainbow__rock_da_pay-</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>114</th>\n",
              "      <td>ORGANIZATION</td>\n",
              "      <td>braggingÂ</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>115</th>\n",
              "      <td>ORGANIZATION</td>\n",
              "      <td>veryÂ Â</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>116 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "              NER                                               Name Count\n",
              "0             GPE                                        en-ger-land     1\n",
              "1             GPE                                        en-ger-land     1\n",
              "2             GPE  brisk_and_vagabond-eyeopener_2007__enviromenta...     1\n",
              "3             GPE                                               u.s.     1\n",
              "4    ORGANIZATION                                               nycÂ     1\n",
              "..            ...                                                ...   ...\n",
              "111  ORGANIZATION                                          vysoÄina     1\n",
              "112  ORGANIZATION                                          euro2016Â     1\n",
              "113           GPE      brisk_and_ham-taste_the_rainbow__rock_da_pay-     1\n",
              "114  ORGANIZATION                                          braggingÂ     1\n",
              "115  ORGANIZATION                                            veryÂ Â     1\n",
              "\n",
              "[116 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KrvKujXpSSSr"
      },
      "source": [
        "NLTK очень плохо отработал. Почти все NER оказались мусором. На очищенных твитах он вообще ничего не искал, только на не предобработанных (заглавные буквы для него важны). Пробовал делать тест, писал в предложении Google и google, и google он не определял, как сущность. Сомнительное выделение NER.\n"
      ]
    }
  ]
}
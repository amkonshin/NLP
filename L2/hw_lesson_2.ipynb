{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "apostrophe_dict = {\n",
    "\"ain't\": \"am not / are not\",\n",
    "\"aren't\": \"are not / am not\",\n",
    "\"can't\": \"cannot\",\n",
    "\"can't've\": \"cannot have\",\n",
    "\"'cause\": \"because\",\n",
    "\"could've\": \"could have\",\n",
    "\"couldn't\": \"could not\",\n",
    "\"couldn't've\": \"could not have\",\n",
    "\"didn't\": \"did not\",\n",
    "\"doesn't\": \"does not\",\n",
    "\"don't\": \"do not\",\n",
    "\"hadn't\": \"had not\",\n",
    "\"hadn't've\": \"had not have\",\n",
    "\"hasn't\": \"has not\",\n",
    "\"haven't\": \"have not\",\n",
    "\"he'd\": \"he had / he would\",\n",
    "\"he'd've\": \"he would have\",\n",
    "\"he'll\": \"he shall / he will\",\n",
    "\"he'll've\": \"he shall have / he will have\",\n",
    "\"he's\": \"he has / he is\",\n",
    "\"how'd\": \"how did\",\n",
    "\"how'd'y\": \"how do you\",\n",
    "\"how'll\": \"how will\",\n",
    "\"how's\": \"how has / how is\",\n",
    "\"i'd\": \"I had / I would\",\n",
    "\"i'd've\": \"I would have\",\n",
    "\"i'll\": \"I shall / I will\",\n",
    "\"i'll've\": \"I shall have / I will have\",\n",
    "\"i'm\": \"I am\",\n",
    "\"i've\": \"I have\",\n",
    "\"isn't\": \"is not\",\n",
    "\"it'd\": \"it had / it would\",\n",
    "\"it'd've\": \"it would have\",\n",
    "\"it'll\": \"it shall / it will\",\n",
    "\"it'll've\": \"it shall have / it will have\",\n",
    "\"it's\": \"it has / it is\",\n",
    "\"let's\": \"let us\",\n",
    "\"ma'am\": \"madam\",\n",
    "\"mayn't\": \"may not\",\n",
    "\"might've\": \"might have\",\n",
    "\"mightn't\": \"might not\",\n",
    "\"mightn't've\": \"might not have\",\n",
    "\"must've\": \"must have\",\n",
    "\"mustn't\": \"must not\",\n",
    "\"mustn't've\": \"must not have\",\n",
    "\"needn't\": \"need not\",\n",
    "\"needn't've\": \"need not have\",\n",
    "\"o'clock\": \"of the clock\",\n",
    "\"oughtn't\": \"ought not\",\n",
    "\"oughtn't've\": \"ought not have\",\n",
    "\"shan't\": \"shall not\",\n",
    "\"sha'n't\": \"shall not\",\n",
    "\"shan't've\": \"shall not have\",\n",
    "\"she'd\": \"she had / she would\",\n",
    "\"she'd've\": \"she would have\",\n",
    "\"she'll\": \"she shall / she will\",\n",
    "\"she'll've\": \"she shall have / she will have\",\n",
    "\"she's\": \"she has / she is\",\n",
    "\"should've\": \"should have\",\n",
    "\"shouldn't\": \"should not\",\n",
    "\"shouldn't've\": \"should not have\",\n",
    "\"so've\": \"so have\",\n",
    "\"so's\": \"so as / so is\",\n",
    "\"that'd\": \"that would / that had\",\n",
    "\"that'd've\": \"that would have\",\n",
    "\"that's\": \"that has / that is\",\n",
    "\"there'd\": \"there had / there would\",\n",
    "\"there'd've\": \"there would have\",\n",
    "\"there's\": \"there has / there is\",\n",
    "\"they'd\": \"they had / they would\",\n",
    "\"they'd've\": \"they would have\",\n",
    "\"they'll\": \"they shall / they will\",\n",
    "\"they'll've\": \"they shall have / they will have\",\n",
    "\"they're\": \"they are\",\n",
    "\"they've\": \"they have\",\n",
    "\"to've\": \"to have\",\n",
    "\"wasn't\": \"was not\",\n",
    "\"we'd\": \"we had / we would\",\n",
    "\"we'd've\": \"we would have\",\n",
    "\"we'll\": \"we will\",\n",
    "\"we'll've\": \"we will have\",\n",
    "\"we're\": \"we are\",\n",
    "\"we've\": \"we have\",\n",
    "\"weren't\": \"were not\",\n",
    "\"what'll\": \"what shall / what will\",\n",
    "\"what'll've\": \"what shall have / what will have\",\n",
    "\"what're\": \"what are\",\n",
    "\"what's\": \"what has / what is\",\n",
    "\"what've\": \"what have\",\n",
    "\"when's\": \"when has / when is\",\n",
    "\"when've\": \"when have\",\n",
    "\"where'd\": \"where did\",\n",
    "\"where's\": \"where has / where is\",\n",
    "\"where've\": \"where have\",\n",
    "\"who'll\": \"who shall / who will\",\n",
    "\"who'll've\": \"who shall have / who will have\",\n",
    "\"who's\": \"who has / who is\",\n",
    "\"who've\": \"who have\",\n",
    "\"why's\": \"why has / why is\",\n",
    "\"why've\": \"why have\",\n",
    "\"will've\": \"will have\",\n",
    "\"won't\": \"will not\",\n",
    "\"won't've\": \"will not have\",\n",
    "\"would've\": \"would have\",\n",
    "\"wouldn't\": \"would not\",\n",
    "\"wouldn't've\": \"would not have\",\n",
    "\"y'all\": \"you all\",\n",
    "\"y'all'd\": \"you all would\",\n",
    "\"y'all'd've\": \"you all would have\",\n",
    "\"y'all're\": \"you all are\",\n",
    "\"y'all've\": \"you all have\",\n",
    "\"you'd\": \"you had / you would\",\n",
    "\"you'd've\": \"you would have\",\n",
    "\"you'll\": \"you shall / you will\",\n",
    "\"you'll've\": \"you shall have / you will have\",\n",
    "\"you're\": \"you are\",\n",
    "\"you've\": \"you have\"\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "short_word_dict = {\n",
    "\"121\": \"one to one\",\n",
    "\"a/s/l\": \"age, sex, location\",\n",
    "\"adn\": \"any day now\",\n",
    "\"afaik\": \"as far as I know\",\n",
    "\"afk\": \"away from keyboard\",\n",
    "\"aight\": \"alright\",\n",
    "\"alol\": \"actually laughing out loud\",\n",
    "\"b4\": \"before\",\n",
    "\"b4n\": \"bye for now\",\n",
    "\"bak\": \"back at the keyboard\",\n",
    "\"bf\": \"boyfriend\",\n",
    "\"bff\": \"best friends forever\",\n",
    "\"bfn\": \"bye for now\",\n",
    "\"bg\": \"big grin\",\n",
    "\"bta\": \"but then again\",\n",
    "\"btw\": \"by the way\",\n",
    "\"cid\": \"crying in disgrace\",\n",
    "\"cnp\": \"continued in my next post\",\n",
    "\"cp\": \"chat post\",\n",
    "\"cu\": \"see you\",\n",
    "\"cul\": \"see you later\",\n",
    "\"cul8r\": \"see you later\",\n",
    "\"cya\": \"bye\",\n",
    "\"cyo\": \"see you online\",\n",
    "\"dbau\": \"doing business as usual\",\n",
    "\"fud\": \"fear, uncertainty, and doubt\",\n",
    "\"fwiw\": \"for what it's worth\",\n",
    "\"fyi\": \"for your information\",\n",
    "\"g\": \"grin\",\n",
    "\"g2g\": \"got to go\",\n",
    "\"ga\": \"go ahead\",\n",
    "\"gal\": \"get a life\",\n",
    "\"gf\": \"girlfriend\",\n",
    "\"gfn\": \"gone for now\",\n",
    "\"gmbo\": \"giggling my butt off\",\n",
    "\"gmta\": \"great minds think alike\",\n",
    "\"h8\": \"hate\",\n",
    "\"hagn\": \"have a good night\",\n",
    "\"hdop\": \"help delete online predators\",\n",
    "\"hhis\": \"hanging head in shame\",\n",
    "\"iac\": \"in any case\",\n",
    "\"ianal\": \"I am not a lawyer\",\n",
    "\"ic\": \"I see\",\n",
    "\"idk\": \"I don't know\",\n",
    "\"imao\": \"in my arrogant opinion\",\n",
    "\"imnsho\": \"in my not so humble opinion\",\n",
    "\"imo\": \"in my opinion\",\n",
    "\"iow\": \"in other words\",\n",
    "\"ipn\": \"I’m posting naked\",\n",
    "\"irl\": \"in real life\",\n",
    "\"jk\": \"just kidding\",\n",
    "\"l8r\": \"later\",\n",
    "\"ld\": \"later, dude\",\n",
    "\"ldr\": \"long distance relationship\",\n",
    "\"llta\": \"lots and lots of thunderous applause\",\n",
    "\"lmao\": \"laugh my ass off\",\n",
    "\"lmirl\": \"let's meet in real life\",\n",
    "\"lol\": \"laugh out loud\",\n",
    "\"ltr\": \"longterm relationship\",\n",
    "\"lulab\": \"love you like a brother\",\n",
    "\"lulas\": \"love you like a sister\",\n",
    "\"luv\": \"love\",\n",
    "\"m/f\": \"male or female\",\n",
    "\"m8\": \"mate\",\n",
    "\"milf\": \"mother I would like to fuck\",\n",
    "\"oll\": \"online love\",\n",
    "\"omg\": \"oh my god\",\n",
    "\"otoh\": \"on the other hand\",\n",
    "\"pir\": \"parent in room\",\n",
    "\"ppl\": \"people\",\n",
    "\"r\": \"are\",\n",
    "\"rofl\": \"roll on the floor laughing\",\n",
    "\"rpg\": \"role playing games\",\n",
    "\"ru\": \"are you\",\n",
    "\"shid\": \"slaps head in disgust\",\n",
    "\"somy\": \"sick of me yet\",\n",
    "\"sot\": \"short of time\",\n",
    "\"thanx\": \"thanks\",\n",
    "\"thx\": \"thanks\",\n",
    "\"ttyl\": \"talk to you later\",\n",
    "\"u\": \"you\",\n",
    "\"ur\": \"you are\",\n",
    "\"uw\": \"you’re welcome\",\n",
    "\"wb\": \"welcome back\",\n",
    "\"wfm\": \"works for me\",\n",
    "\"wibni\": \"wouldn't it be nice if\",\n",
    "\"wtf\": \"what the fuck\",\n",
    "\"wtg\": \"way to go\",\n",
    "\"wtgp\": \"want to go private\",\n",
    "\"ym\": \"young man\",\n",
    "\"gr8\": \"great\"\n",
    "}\n",
    "\n",
    "\n",
    "emoticon_dict = {\n",
    "\":)\": \"happy\",\n",
    "\":‑)\": \"happy\",\n",
    "\":-]\": \"happy\",\n",
    "\":-3\": \"happy\",\n",
    "\":->\": \"happy\",\n",
    "\"8-)\": \"happy\",\n",
    "\":-}\": \"happy\",\n",
    "\":o)\": \"happy\",\n",
    "\":c)\": \"happy\",\n",
    "\":^)\": \"happy\",\n",
    "\"=]\": \"happy\",\n",
    "\"=)\": \"happy\",\n",
    "\"<3\": \"happy\",\n",
    "\":-(\": \"sad\",\n",
    "\":(\": \"sad\",\n",
    "\":c\": \"sad\",\n",
    "\":<\": \"sad\",\n",
    "\":[\": \"sad\",\n",
    "\">:[\": \"sad\",\n",
    "\":{\": \"sad\",\n",
    "\">:(\": \"sad\",\n",
    "\":-c\": \"sad\",\n",
    "\":-< \": \"sad\",\n",
    "\":-[\": \"sad\",\n",
    "\":-||\": \"sad\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet\n",
       "0   1      0   @user when a father is dysfunctional and is s...\n",
       "1   2      0  @user @user thanks for #lyft credit i can't us...\n",
       "2   3      0                                bihday your majesty\n",
       "3   4      0  #model   i love u take with u all the time in ...\n",
       "4   5      0             factsguide: society now    #motivation"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('train_tweets.csv')\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>31963</td>\n",
       "      <td>#studiolife #aislife #requires #passion #dedic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>31964</td>\n",
       "      <td>@user #white #supremacists want everyone to s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>31965</td>\n",
       "      <td>safe ways to heal your #acne!!    #altwaystohe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>31966</td>\n",
       "      <td>is the hp and the cursed child book up for res...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>31967</td>\n",
       "      <td>3rd #bihday to my amazing, hilarious #nephew...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                              tweet\n",
       "0  31963  #studiolife #aislife #requires #passion #dedic...\n",
       "1  31964   @user #white #supremacists want everyone to s...\n",
       "2  31965  safe ways to heal your #acne!!    #altwaystohe...\n",
       "3  31966  is the hp and the cursed child book up for res...\n",
       "4  31967    3rd #bihday to my amazing, hilarious #nephew..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv('test_tweets.csv')\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[2/2] huge fan fare and big talking before the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>@user camping tomorrow @user @user @user @use...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>the next school year is the year for exams.ð...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>we won!!! love the land!!! #allin #cavs #champ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>@user @user welcome here !  i'm   it's so #gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>â #ireland consumer price index (mom) climb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>we are so selfish. #orlando #standwithorlando ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>i get to see my daddy today!!   #80days #getti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>1.0</td>\n",
       "      <td>@user #cnn calls #michigan middle school 'buil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>1.0</td>\n",
       "      <td>no comment!  in #australia   #opkillingbay #se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ouch...junior is angryð#got7 #junior #yugyo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>i am thankful for having a paner. #thankful #p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>1.0</td>\n",
       "      <td>retweet if you agree!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>its #friday! ð smiles all around via ig use...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>as we all know, essential oils are not made of...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  label                                              tweet\n",
       "0    1    0.0   @user when a father is dysfunctional and is s...\n",
       "1    2    0.0  @user @user thanks for #lyft credit i can't us...\n",
       "2    3    0.0                                bihday your majesty\n",
       "3    4    0.0  #model   i love u take with u all the time in ...\n",
       "4    5    0.0             factsguide: society now    #motivation\n",
       "5    6    0.0  [2/2] huge fan fare and big talking before the...\n",
       "6    7    0.0   @user camping tomorrow @user @user @user @use...\n",
       "7    8    0.0  the next school year is the year for exams.ð...\n",
       "8    9    0.0  we won!!! love the land!!! #allin #cavs #champ...\n",
       "9   10    0.0   @user @user welcome here !  i'm   it's so #gr...\n",
       "10  11    0.0   â #ireland consumer price index (mom) climb...\n",
       "11  12    0.0  we are so selfish. #orlando #standwithorlando ...\n",
       "12  13    0.0  i get to see my daddy today!!   #80days #getti...\n",
       "13  14    1.0  @user #cnn calls #michigan middle school 'buil...\n",
       "14  15    1.0  no comment!  in #australia   #opkillingbay #se...\n",
       "15  16    0.0  ouch...junior is angryð#got7 #junior #yugyo...\n",
       "16  17    0.0  i am thankful for having a paner. #thankful #p...\n",
       "17  18    1.0                             retweet if you agree! \n",
       "18  19    0.0  its #friday! ð smiles all around via ig use...\n",
       "19  20    0.0  as we all know, essential oils are not made of..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combine_df = train_df.append(test_df, ignore_index = True, sort = False)\n",
    "combine_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 49159 entries, 0 to 49158\n",
      "Data columns (total 3 columns):\n",
      "id       49159 non-null int64\n",
      "label    31962 non-null float64\n",
      "tweet    49159 non-null object\n",
      "dtypes: float64(1), int64(1), object(1)\n",
      "memory usage: 960.2+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(combine_df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Заменим html-сущности (к примеру: &lt; &gt; &amp;). \"&lt;\" заменим на “<” и \"&amp;\" заменим на “&”)\"\"\". Сделаем это с помощью HTMLParser.unescape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_df['clear_tweet']=combine_df['tweet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import html.parser   \n",
    "def findHTML(tweets):\n",
    "    clean_tweets=[]\n",
    "    for tweet in tweets:\n",
    "        tweet=html.unescape(str(tweet))\n",
    "        clean_tweets.append(tweet)\n",
    "    return clean_tweets\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_df['clear_tweet']=findHTML(np.array(combine_df['clear_tweet']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Удалим @user из всех твитов с помощью паттерна \"@[\\w]*\". Для этого создадим функцию: \n",
    " - для того, чтобы найти все вхождения паттерна в тексте, необходимо использовать re.findall(pattern, input_txt)\n",
    " - для для замены @user на пробел, необходимо использовать re.sub()\n",
    "при применении функции необходимо использовать np.vectorize(function)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_user(tweets):\n",
    "    \n",
    "    clean_tweets=[]\n",
    "    for tweet in tweets:\n",
    "        tweet=re.sub('@[\\w]*','',tweet)\n",
    "        clean_tweets.append(tweet)\n",
    "    return clean_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_df['clear_tweet']=delete_user(np.array(combine_df['clear_tweet']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>clear_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "      <td>when a father is dysfunctional and is so sel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "      <td>thanks for #lyft credit i can't use cause th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49154</td>\n",
       "      <td>49155</td>\n",
       "      <td>NaN</td>\n",
       "      <td>thought factory: left-right polarisation! #tru...</td>\n",
       "      <td>thought factory: left-right polarisation! #tru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49155</td>\n",
       "      <td>49156</td>\n",
       "      <td>NaN</td>\n",
       "      <td>feeling like a mermaid ð #hairflip #neverre...</td>\n",
       "      <td>feeling like a mermaid ð #hairflip #neverre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49156</td>\n",
       "      <td>49157</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#hillary #campaigned today in #ohio((omg)) &amp;am...</td>\n",
       "      <td>#hillary #campaigned today in #ohio((omg)) &amp; u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49157</td>\n",
       "      <td>49158</td>\n",
       "      <td>NaN</td>\n",
       "      <td>happy, at work conference: right mindset leads...</td>\n",
       "      <td>happy, at work conference: right mindset leads...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49158</td>\n",
       "      <td>49159</td>\n",
       "      <td>NaN</td>\n",
       "      <td>my   song \"so glad\" free download!  #shoegaze ...</td>\n",
       "      <td>my   song \"so glad\" free download!  #shoegaze ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49159 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  label                                              tweet  \\\n",
       "0          1    0.0   @user when a father is dysfunctional and is s...   \n",
       "1          2    0.0  @user @user thanks for #lyft credit i can't us...   \n",
       "2          3    0.0                                bihday your majesty   \n",
       "3          4    0.0  #model   i love u take with u all the time in ...   \n",
       "4          5    0.0             factsguide: society now    #motivation   \n",
       "...      ...    ...                                                ...   \n",
       "49154  49155    NaN  thought factory: left-right polarisation! #tru...   \n",
       "49155  49156    NaN  feeling like a mermaid ð #hairflip #neverre...   \n",
       "49156  49157    NaN  #hillary #campaigned today in #ohio((omg)) &am...   \n",
       "49157  49158    NaN  happy, at work conference: right mindset leads...   \n",
       "49158  49159    NaN  my   song \"so glad\" free download!  #shoegaze ...   \n",
       "\n",
       "                                             clear_tweet  \n",
       "0        when a father is dysfunctional and is so sel...  \n",
       "1        thanks for #lyft credit i can't use cause th...  \n",
       "2                                    bihday your majesty  \n",
       "3      #model   i love u take with u all the time in ...  \n",
       "4                 factsguide: society now    #motivation  \n",
       "...                                                  ...  \n",
       "49154  thought factory: left-right polarisation! #tru...  \n",
       "49155  feeling like a mermaid ð #hairflip #neverre...  \n",
       "49156  #hillary #campaigned today in #ohio((omg)) & u...  \n",
       "49157  happy, at work conference: right mindset leads...  \n",
       "49158  my   song \"so glad\" free download!  #shoegaze ...  \n",
       "\n",
       "[49159 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combine_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Изменим регистр твитов на нижний с помощью .lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lower_tweet(tweets):\n",
    "    \n",
    "    clean_tweets=[]\n",
    "    for tweet in tweets:\n",
    "        tweet=tweet.lower()\n",
    "        clean_tweets.append(tweet)\n",
    "    return clean_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_df['clear_tweet']=lower_tweet(np.array(combine_df['clear_tweet']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Заменим сокращения с апострофами (пример: ain't, can't) на пробел, используя apostrophe_dict. Для этого необходимо сделать функцию: для каждого слова в тексте проверить (for word in text.split()), если слово есть в словаре apostrophe_dict в качестве ключа (сокращенного слова), то заменить ключ на значение (полную версию слова)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apostrophe_reduction(tweets, apostrophe_dict):\n",
    "    clean_tweets=[]\n",
    "    for tweet in tweets:\n",
    "        for word in set(tweet.split()):\n",
    "            if word in apostrophe_dict.keys():\n",
    "                tweet=re.sub(word,apostrophe_dict[word],tweet)\n",
    "        clean_tweets.append(tweet)\n",
    "    return clean_tweets\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_df['clear_tweet']=apostrophe_reduction(np.array(combine_df['clear_tweet']),apostrophe_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Заменим сокращения на их полные формы, используя short_word_dict. Для этого воспользуемся функцией, используемой в предыдущем пункте."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def short_words(tweets, short_word_dict):\n",
    "    clean_tweets=[]\n",
    "    for tweet in tweets:\n",
    "        for word in set(tweet.split()):\n",
    "            if word in short_word_dict.keys():\n",
    "                tweet=re.sub(word,short_word_dict[word],tweet)\n",
    "        clean_tweets.append(tweet)\n",
    "    return clean_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_df['clear_tweet']=short_words(np.array(combine_df['clear_tweet']),short_word_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>clear_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "      <td>when a father is dysfunctional and is so sel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "      <td>thanks for #lyft credit i cannot use cause t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "      <td>#model   i love you take with you all the time...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49154</td>\n",
       "      <td>49155</td>\n",
       "      <td>NaN</td>\n",
       "      <td>thought factory: left-right polarisation! #tru...</td>\n",
       "      <td>thought factory: left-right polarisation! #tru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49155</td>\n",
       "      <td>49156</td>\n",
       "      <td>NaN</td>\n",
       "      <td>feeling like a mermaid ð #hairflip #neverre...</td>\n",
       "      <td>feeling like a mermaid ð #hairflip #neverre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49156</td>\n",
       "      <td>49157</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#hillary #campaigned today in #ohio((omg)) &amp;am...</td>\n",
       "      <td>#hillary #campaigned today in #ohio((omg)) &amp; u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49157</td>\n",
       "      <td>49158</td>\n",
       "      <td>NaN</td>\n",
       "      <td>happy, at work conference: right mindset leads...</td>\n",
       "      <td>happy, at work conference: right mindset leads...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49158</td>\n",
       "      <td>49159</td>\n",
       "      <td>NaN</td>\n",
       "      <td>my   song \"so glad\" free download!  #shoegaze ...</td>\n",
       "      <td>my   song \"so glad\" free download!  #shoegaze ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49159 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  label                                              tweet  \\\n",
       "0          1    0.0   @user when a father is dysfunctional and is s...   \n",
       "1          2    0.0  @user @user thanks for #lyft credit i can't us...   \n",
       "2          3    0.0                                bihday your majesty   \n",
       "3          4    0.0  #model   i love u take with u all the time in ...   \n",
       "4          5    0.0             factsguide: society now    #motivation   \n",
       "...      ...    ...                                                ...   \n",
       "49154  49155    NaN  thought factory: left-right polarisation! #tru...   \n",
       "49155  49156    NaN  feeling like a mermaid ð #hairflip #neverre...   \n",
       "49156  49157    NaN  #hillary #campaigned today in #ohio((omg)) &am...   \n",
       "49157  49158    NaN  happy, at work conference: right mindset leads...   \n",
       "49158  49159    NaN  my   song \"so glad\" free download!  #shoegaze ...   \n",
       "\n",
       "                                             clear_tweet  \n",
       "0        when a father is dysfunctional and is so sel...  \n",
       "1        thanks for #lyft credit i cannot use cause t...  \n",
       "2                                    bihday your majesty  \n",
       "3      #model   i love you take with you all the time...  \n",
       "4                 factsguide: society now    #motivation  \n",
       "...                                                  ...  \n",
       "49154  thought factory: left-right polarisation! #tru...  \n",
       "49155  feeling like a mermaid ð #hairflip #neverre...  \n",
       "49156  #hillary #campaigned today in #ohio((omg)) & u...  \n",
       "49157  happy, at work conference: right mindset leads...  \n",
       "49158  my   song \"so glad\" free download!  #shoegaze ...  \n",
       "\n",
       "[49159 rows x 4 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combine_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Заменим эмотиконы (пример: \":)\" = \"happy\") на пробелы, используя emoticon_dict. Для этого воспользуемся функцией, используемой в предыдущем пункте."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def emotion_words(tweets, emoticon_dict):\n",
    "    clean_tweets=[]\n",
    "    for tweet in tweets:\n",
    "        for word in set(tweet.split()):\n",
    "            if word in emoticon_dict.keys():\n",
    "                tweet=tweet.replace(word,emoticon_dict[word])\n",
    "        clean_tweets.append(tweet)\n",
    "    return clean_tweets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_df['clear_tweet']=emotion_words(np.array(combine_df['clear_tweet']),emoticon_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>clear_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "      <td>when a father is dysfunctional and is so sel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "      <td>thanks for #lyft credit i cannot use cause t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "      <td>#model   i love you take with you all the time...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49154</td>\n",
       "      <td>49155</td>\n",
       "      <td>NaN</td>\n",
       "      <td>thought factory: left-right polarisation! #tru...</td>\n",
       "      <td>thought factory: left-right polarisation! #tru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49155</td>\n",
       "      <td>49156</td>\n",
       "      <td>NaN</td>\n",
       "      <td>feeling like a mermaid ð #hairflip #neverre...</td>\n",
       "      <td>feeling like a mermaid ð #hairflip #neverre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49156</td>\n",
       "      <td>49157</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#hillary #campaigned today in #ohio((omg)) &amp;am...</td>\n",
       "      <td>#hillary #campaigned today in #ohio((omg)) &amp; u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49157</td>\n",
       "      <td>49158</td>\n",
       "      <td>NaN</td>\n",
       "      <td>happy, at work conference: right mindset leads...</td>\n",
       "      <td>happy, at work conference: right mindset leads...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49158</td>\n",
       "      <td>49159</td>\n",
       "      <td>NaN</td>\n",
       "      <td>my   song \"so glad\" free download!  #shoegaze ...</td>\n",
       "      <td>my   song \"so glad\" free download!  #shoegaze ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49159 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  label                                              tweet  \\\n",
       "0          1    0.0   @user when a father is dysfunctional and is s...   \n",
       "1          2    0.0  @user @user thanks for #lyft credit i can't us...   \n",
       "2          3    0.0                                bihday your majesty   \n",
       "3          4    0.0  #model   i love u take with u all the time in ...   \n",
       "4          5    0.0             factsguide: society now    #motivation   \n",
       "...      ...    ...                                                ...   \n",
       "49154  49155    NaN  thought factory: left-right polarisation! #tru...   \n",
       "49155  49156    NaN  feeling like a mermaid ð #hairflip #neverre...   \n",
       "49156  49157    NaN  #hillary #campaigned today in #ohio((omg)) &am...   \n",
       "49157  49158    NaN  happy, at work conference: right mindset leads...   \n",
       "49158  49159    NaN  my   song \"so glad\" free download!  #shoegaze ...   \n",
       "\n",
       "                                             clear_tweet  \n",
       "0        when a father is dysfunctional and is so sel...  \n",
       "1        thanks for #lyft credit i cannot use cause t...  \n",
       "2                                    bihday your majesty  \n",
       "3      #model   i love you take with you all the time...  \n",
       "4                 factsguide: society now    #motivation  \n",
       "...                                                  ...  \n",
       "49154  thought factory: left-right polarisation! #tru...  \n",
       "49155  feeling like a mermaid ð #hairflip #neverre...  \n",
       "49156  #hillary #campaigned today in #ohio((omg)) & u...  \n",
       "49157  happy, at work conference: right mindset leads...  \n",
       "49158  my   song \"so glad\" free download!  #shoegaze ...  \n",
       "\n",
       "[49159 rows x 4 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combine_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Заменим пунктуацию на пробелы, используя re.sub() и паттерн r'[^\\w\\s]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def punctuation(tweets):\n",
    "    clean_tweets=[]\n",
    "    for tweet in tweets:\n",
    "        tweet=re.sub(r'[^\\w\\s]',' ',tweet)\n",
    "        clean_tweets.append(tweet)\n",
    "    return clean_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_df['clear_tweet']=punctuation(np.array(combine_df['clear_tweet']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Заменим спец. символы на пробелы, используя re.sub() и паттерн r'[^a-zA-Z0-9]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spec_punctuation(tweets):\n",
    "    clean_tweets=[]\n",
    "    for tweet in tweets:\n",
    "        tweet=re.sub(r'[^a-zA-Z0-9]',' ',tweet)\n",
    "        clean_tweets.append(tweet)\n",
    "    return clean_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_df['clear_tweet']=spec_punctuation(np.array(combine_df['clear_tweet']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Заменим числа на пробелы, используя re.sub() и паттерн r'[^a-zA-Z]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numbers(tweets):\n",
    "    clean_tweets=[]\n",
    "    for tweet in tweets:\n",
    "        tweet=re.sub(r'[^a-zA-Z]',' ',tweet)\n",
    "        clean_tweets.append(tweet)\n",
    "    return clean_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_df['clear_tweet']=numbers(np.array(combine_df['clear_tweet']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>clear_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "      <td>when a father is dysfunctional and is so sel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "      <td>thanks for  lyft credit i cannot use cause t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "      <td>model   i love you take with you all the time...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "      <td>factsguide  society now     motivation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49154</td>\n",
       "      <td>49155</td>\n",
       "      <td>NaN</td>\n",
       "      <td>thought factory: left-right polarisation! #tru...</td>\n",
       "      <td>thought factory  left right polarisation   tru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49155</td>\n",
       "      <td>49156</td>\n",
       "      <td>NaN</td>\n",
       "      <td>feeling like a mermaid ð #hairflip #neverre...</td>\n",
       "      <td>feeling like a mermaid       hairflip  neverre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49156</td>\n",
       "      <td>49157</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#hillary #campaigned today in #ohio((omg)) &amp;am...</td>\n",
       "      <td>hillary  campaigned today in  ohio  omg     u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49157</td>\n",
       "      <td>49158</td>\n",
       "      <td>NaN</td>\n",
       "      <td>happy, at work conference: right mindset leads...</td>\n",
       "      <td>happy  at work conference  right mindset leads...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49158</td>\n",
       "      <td>49159</td>\n",
       "      <td>NaN</td>\n",
       "      <td>my   song \"so glad\" free download!  #shoegaze ...</td>\n",
       "      <td>my   song  so glad  free download    shoegaze ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49159 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  label                                              tweet  \\\n",
       "0          1    0.0   @user when a father is dysfunctional and is s...   \n",
       "1          2    0.0  @user @user thanks for #lyft credit i can't us...   \n",
       "2          3    0.0                                bihday your majesty   \n",
       "3          4    0.0  #model   i love u take with u all the time in ...   \n",
       "4          5    0.0             factsguide: society now    #motivation   \n",
       "...      ...    ...                                                ...   \n",
       "49154  49155    NaN  thought factory: left-right polarisation! #tru...   \n",
       "49155  49156    NaN  feeling like a mermaid ð #hairflip #neverre...   \n",
       "49156  49157    NaN  #hillary #campaigned today in #ohio((omg)) &am...   \n",
       "49157  49158    NaN  happy, at work conference: right mindset leads...   \n",
       "49158  49159    NaN  my   song \"so glad\" free download!  #shoegaze ...   \n",
       "\n",
       "                                             clear_tweet  \n",
       "0        when a father is dysfunctional and is so sel...  \n",
       "1        thanks for  lyft credit i cannot use cause t...  \n",
       "2                                    bihday your majesty  \n",
       "3       model   i love you take with you all the time...  \n",
       "4                 factsguide  society now     motivation  \n",
       "...                                                  ...  \n",
       "49154  thought factory  left right polarisation   tru...  \n",
       "49155  feeling like a mermaid       hairflip  neverre...  \n",
       "49156   hillary  campaigned today in  ohio  omg     u...  \n",
       "49157  happy  at work conference  right mindset leads...  \n",
       "49158  my   song  so glad  free download    shoegaze ...  \n",
       "\n",
       "[49159 rows x 4 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combine_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Удалим из текста слова длиной в 1 символ, используя ' '.join([w for w in x.split() if len(w)>1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one(tweets):\n",
    "    clean_tweets=[]\n",
    "    for tweet in tweets:\n",
    "        tweet=' '.join([w for w in tweet.split() if len(w)>1])\n",
    "        clean_tweets.append(tweet)\n",
    "    return clean_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_df['clear_tweet']=one(np.array(combine_df['clear_tweet']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>clear_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "      <td>when father is dysfunctional and is so selfish...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "      <td>thanks for lyft credit cannot use cause they d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "      <td>model love you take with you all the time in your</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "      <td>factsguide society now motivation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49154</td>\n",
       "      <td>49155</td>\n",
       "      <td>NaN</td>\n",
       "      <td>thought factory: left-right polarisation! #tru...</td>\n",
       "      <td>thought factory left right polarisation trump ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49155</td>\n",
       "      <td>49156</td>\n",
       "      <td>NaN</td>\n",
       "      <td>feeling like a mermaid ð #hairflip #neverre...</td>\n",
       "      <td>feeling like mermaid hairflip neverready forma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49156</td>\n",
       "      <td>49157</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#hillary #campaigned today in #ohio((omg)) &amp;am...</td>\n",
       "      <td>hillary campaigned today in ohio omg used word...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49157</td>\n",
       "      <td>49158</td>\n",
       "      <td>NaN</td>\n",
       "      <td>happy, at work conference: right mindset leads...</td>\n",
       "      <td>happy at work conference right mindset leads t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49158</td>\n",
       "      <td>49159</td>\n",
       "      <td>NaN</td>\n",
       "      <td>my   song \"so glad\" free download!  #shoegaze ...</td>\n",
       "      <td>my song so glad free download shoegaze newmusi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49159 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  label                                              tweet  \\\n",
       "0          1    0.0   @user when a father is dysfunctional and is s...   \n",
       "1          2    0.0  @user @user thanks for #lyft credit i can't us...   \n",
       "2          3    0.0                                bihday your majesty   \n",
       "3          4    0.0  #model   i love u take with u all the time in ...   \n",
       "4          5    0.0             factsguide: society now    #motivation   \n",
       "...      ...    ...                                                ...   \n",
       "49154  49155    NaN  thought factory: left-right polarisation! #tru...   \n",
       "49155  49156    NaN  feeling like a mermaid ð #hairflip #neverre...   \n",
       "49156  49157    NaN  #hillary #campaigned today in #ohio((omg)) &am...   \n",
       "49157  49158    NaN  happy, at work conference: right mindset leads...   \n",
       "49158  49159    NaN  my   song \"so glad\" free download!  #shoegaze ...   \n",
       "\n",
       "                                             clear_tweet  \n",
       "0      when father is dysfunctional and is so selfish...  \n",
       "1      thanks for lyft credit cannot use cause they d...  \n",
       "2                                    bihday your majesty  \n",
       "3      model love you take with you all the time in your  \n",
       "4                      factsguide society now motivation  \n",
       "...                                                  ...  \n",
       "49154  thought factory left right polarisation trump ...  \n",
       "49155  feeling like mermaid hairflip neverready forma...  \n",
       "49156  hillary campaigned today in ohio omg used word...  \n",
       "49157  happy at work conference right mindset leads t...  \n",
       "49158  my song so glad free download shoegaze newmusi...  \n",
       "\n",
       "[49159 rows x 4 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combine_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. Поделим твиты на токены с помощью nltk.tokenize.word_tokenize, создав новый столбец 'tweet_token'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from nltk import tokenize as tknz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\AKonshini\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_tokens(tweets):\n",
    "    clean_tweets=[]\n",
    "    for tweet in tweets:\n",
    "        tweet=tknz.word_tokenize(tweet)\n",
    "        clean_tweets.append(tweet)\n",
    "    return clean_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_df['tweet_token']=word_tokens(np.array(combine_df['clear_tweet']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>clear_tweet</th>\n",
       "      <th>tweet_token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "      <td>when father is dysfunctional and is so selfish...</td>\n",
       "      <td>[when, father, is, dysfunctional, and, is, so,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "      <td>thanks for lyft credit cannot use cause they d...</td>\n",
       "      <td>[thanks, for, lyft, credit, can, not, use, cau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>[bihday, your, majesty]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "      <td>model love you take with you all the time in your</td>\n",
       "      <td>[model, love, you, take, with, you, all, the, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "      <td>factsguide society now motivation</td>\n",
       "      <td>[factsguide, society, now, motivation]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49154</td>\n",
       "      <td>49155</td>\n",
       "      <td>NaN</td>\n",
       "      <td>thought factory: left-right polarisation! #tru...</td>\n",
       "      <td>thought factory left right polarisation trump ...</td>\n",
       "      <td>[thought, factory, left, right, polarisation, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49155</td>\n",
       "      <td>49156</td>\n",
       "      <td>NaN</td>\n",
       "      <td>feeling like a mermaid ð #hairflip #neverre...</td>\n",
       "      <td>feeling like mermaid hairflip neverready forma...</td>\n",
       "      <td>[feeling, like, mermaid, hairflip, neverready,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49156</td>\n",
       "      <td>49157</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#hillary #campaigned today in #ohio((omg)) &amp;am...</td>\n",
       "      <td>hillary campaigned today in ohio omg used word...</td>\n",
       "      <td>[hillary, campaigned, today, in, ohio, omg, us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49157</td>\n",
       "      <td>49158</td>\n",
       "      <td>NaN</td>\n",
       "      <td>happy, at work conference: right mindset leads...</td>\n",
       "      <td>happy at work conference right mindset leads t...</td>\n",
       "      <td>[happy, at, work, conference, right, mindset, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49158</td>\n",
       "      <td>49159</td>\n",
       "      <td>NaN</td>\n",
       "      <td>my   song \"so glad\" free download!  #shoegaze ...</td>\n",
       "      <td>my song so glad free download shoegaze newmusi...</td>\n",
       "      <td>[my, song, so, glad, free, download, shoegaze,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49159 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  label                                              tweet  \\\n",
       "0          1    0.0   @user when a father is dysfunctional and is s...   \n",
       "1          2    0.0  @user @user thanks for #lyft credit i can't us...   \n",
       "2          3    0.0                                bihday your majesty   \n",
       "3          4    0.0  #model   i love u take with u all the time in ...   \n",
       "4          5    0.0             factsguide: society now    #motivation   \n",
       "...      ...    ...                                                ...   \n",
       "49154  49155    NaN  thought factory: left-right polarisation! #tru...   \n",
       "49155  49156    NaN  feeling like a mermaid ð #hairflip #neverre...   \n",
       "49156  49157    NaN  #hillary #campaigned today in #ohio((omg)) &am...   \n",
       "49157  49158    NaN  happy, at work conference: right mindset leads...   \n",
       "49158  49159    NaN  my   song \"so glad\" free download!  #shoegaze ...   \n",
       "\n",
       "                                             clear_tweet  \\\n",
       "0      when father is dysfunctional and is so selfish...   \n",
       "1      thanks for lyft credit cannot use cause they d...   \n",
       "2                                    bihday your majesty   \n",
       "3      model love you take with you all the time in your   \n",
       "4                      factsguide society now motivation   \n",
       "...                                                  ...   \n",
       "49154  thought factory left right polarisation trump ...   \n",
       "49155  feeling like mermaid hairflip neverready forma...   \n",
       "49156  hillary campaigned today in ohio omg used word...   \n",
       "49157  happy at work conference right mindset leads t...   \n",
       "49158  my song so glad free download shoegaze newmusi...   \n",
       "\n",
       "                                             tweet_token  \n",
       "0      [when, father, is, dysfunctional, and, is, so,...  \n",
       "1      [thanks, for, lyft, credit, can, not, use, cau...  \n",
       "2                                [bihday, your, majesty]  \n",
       "3      [model, love, you, take, with, you, all, the, ...  \n",
       "4                 [factsguide, society, now, motivation]  \n",
       "...                                                  ...  \n",
       "49154  [thought, factory, left, right, polarisation, ...  \n",
       "49155  [feeling, like, mermaid, hairflip, neverready,...  \n",
       "49156  [hillary, campaigned, today, in, ohio, omg, us...  \n",
       "49157  [happy, at, work, conference, right, mindset, ...  \n",
       "49158  [my, song, so, glad, free, download, shoegaze,...  \n",
       "\n",
       "[49159 rows x 5 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combine_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. Удалим стоп-слова из токенов, используя nltk.corpus.stopwords. Создадим столбец 'tweet_token_filtered' без стоп-слов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\AKonshini\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stor_word_tokens(tweets):\n",
    "    clean_tweets=[]\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    for tweet in tweets:\n",
    "        tweet=[word for word  in tweet if not word in stop_words]\n",
    "        \n",
    "        clean_tweets.append(tweet)\n",
    "    return clean_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_df['tweet_token_filtered']=stor_word_tokens(np.array(combine_df['tweet_token']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>clear_tweet</th>\n",
       "      <th>tweet_token</th>\n",
       "      <th>tweet_token_filtered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "      <td>when father is dysfunctional and is so selfish...</td>\n",
       "      <td>[when, father, is, dysfunctional, and, is, so,...</td>\n",
       "      <td>[father, dysfunctional, selfish, drags, kids, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "      <td>thanks for lyft credit cannot use cause they d...</td>\n",
       "      <td>[thanks, for, lyft, credit, can, not, use, cau...</td>\n",
       "      <td>[thanks, lyft, credit, use, cause, offer, whee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>[bihday, your, majesty]</td>\n",
       "      <td>[bihday, majesty]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "      <td>model love you take with you all the time in your</td>\n",
       "      <td>[model, love, you, take, with, you, all, the, ...</td>\n",
       "      <td>[model, love, take, time]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "      <td>factsguide society now motivation</td>\n",
       "      <td>[factsguide, society, now, motivation]</td>\n",
       "      <td>[factsguide, society, motivation]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49154</td>\n",
       "      <td>49155</td>\n",
       "      <td>NaN</td>\n",
       "      <td>thought factory: left-right polarisation! #tru...</td>\n",
       "      <td>thought factory left right polarisation trump ...</td>\n",
       "      <td>[thought, factory, left, right, polarisation, ...</td>\n",
       "      <td>[thought, factory, left, right, polarisation, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49155</td>\n",
       "      <td>49156</td>\n",
       "      <td>NaN</td>\n",
       "      <td>feeling like a mermaid ð #hairflip #neverre...</td>\n",
       "      <td>feeling like mermaid hairflip neverready forma...</td>\n",
       "      <td>[feeling, like, mermaid, hairflip, neverready,...</td>\n",
       "      <td>[feeling, like, mermaid, hairflip, neverready,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49156</td>\n",
       "      <td>49157</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#hillary #campaigned today in #ohio((omg)) &amp;am...</td>\n",
       "      <td>hillary campaigned today in ohio omg used word...</td>\n",
       "      <td>[hillary, campaigned, today, in, ohio, omg, us...</td>\n",
       "      <td>[hillary, campaigned, today, ohio, omg, used, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49157</td>\n",
       "      <td>49158</td>\n",
       "      <td>NaN</td>\n",
       "      <td>happy, at work conference: right mindset leads...</td>\n",
       "      <td>happy at work conference right mindset leads t...</td>\n",
       "      <td>[happy, at, work, conference, right, mindset, ...</td>\n",
       "      <td>[happy, work, conference, right, mindset, lead...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49158</td>\n",
       "      <td>49159</td>\n",
       "      <td>NaN</td>\n",
       "      <td>my   song \"so glad\" free download!  #shoegaze ...</td>\n",
       "      <td>my song so glad free download shoegaze newmusi...</td>\n",
       "      <td>[my, song, so, glad, free, download, shoegaze,...</td>\n",
       "      <td>[song, glad, free, download, shoegaze, newmusi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49159 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  label                                              tweet  \\\n",
       "0          1    0.0   @user when a father is dysfunctional and is s...   \n",
       "1          2    0.0  @user @user thanks for #lyft credit i can't us...   \n",
       "2          3    0.0                                bihday your majesty   \n",
       "3          4    0.0  #model   i love u take with u all the time in ...   \n",
       "4          5    0.0             factsguide: society now    #motivation   \n",
       "...      ...    ...                                                ...   \n",
       "49154  49155    NaN  thought factory: left-right polarisation! #tru...   \n",
       "49155  49156    NaN  feeling like a mermaid ð #hairflip #neverre...   \n",
       "49156  49157    NaN  #hillary #campaigned today in #ohio((omg)) &am...   \n",
       "49157  49158    NaN  happy, at work conference: right mindset leads...   \n",
       "49158  49159    NaN  my   song \"so glad\" free download!  #shoegaze ...   \n",
       "\n",
       "                                             clear_tweet  \\\n",
       "0      when father is dysfunctional and is so selfish...   \n",
       "1      thanks for lyft credit cannot use cause they d...   \n",
       "2                                    bihday your majesty   \n",
       "3      model love you take with you all the time in your   \n",
       "4                      factsguide society now motivation   \n",
       "...                                                  ...   \n",
       "49154  thought factory left right polarisation trump ...   \n",
       "49155  feeling like mermaid hairflip neverready forma...   \n",
       "49156  hillary campaigned today in ohio omg used word...   \n",
       "49157  happy at work conference right mindset leads t...   \n",
       "49158  my song so glad free download shoegaze newmusi...   \n",
       "\n",
       "                                             tweet_token  \\\n",
       "0      [when, father, is, dysfunctional, and, is, so,...   \n",
       "1      [thanks, for, lyft, credit, can, not, use, cau...   \n",
       "2                                [bihday, your, majesty]   \n",
       "3      [model, love, you, take, with, you, all, the, ...   \n",
       "4                 [factsguide, society, now, motivation]   \n",
       "...                                                  ...   \n",
       "49154  [thought, factory, left, right, polarisation, ...   \n",
       "49155  [feeling, like, mermaid, hairflip, neverready,...   \n",
       "49156  [hillary, campaigned, today, in, ohio, omg, us...   \n",
       "49157  [happy, at, work, conference, right, mindset, ...   \n",
       "49158  [my, song, so, glad, free, download, shoegaze,...   \n",
       "\n",
       "                                    tweet_token_filtered  \n",
       "0      [father, dysfunctional, selfish, drags, kids, ...  \n",
       "1      [thanks, lyft, credit, use, cause, offer, whee...  \n",
       "2                                      [bihday, majesty]  \n",
       "3                              [model, love, take, time]  \n",
       "4                      [factsguide, society, motivation]  \n",
       "...                                                  ...  \n",
       "49154  [thought, factory, left, right, polarisation, ...  \n",
       "49155  [feeling, like, mermaid, hairflip, neverready,...  \n",
       "49156  [hillary, campaigned, today, ohio, omg, used, ...  \n",
       "49157  [happy, work, conference, right, mindset, lead...  \n",
       "49158  [song, glad, free, download, shoegaze, newmusi...  \n",
       "\n",
       "[49159 rows x 6 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combine_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13. Применим стемминг к токенам с помощью nltk.stem.PorterStemmer. Создадим столбец 'tweet_stemmed' после применения стемминга."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer,WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemmed_word_tokens(tweets):\n",
    "    clean_tweets=[]\n",
    "    stemmer=PorterStemmer()\n",
    "    for tweet in tweets:\n",
    "        tweet=[stemmer.stem(word) for word  in tweet]\n",
    "        \n",
    "        clean_tweets.append(tweet)\n",
    "    return clean_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_df['tweet_stemmed']=stemmed_word_tokens(np.array(combine_df['tweet_token_filtered']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>clear_tweet</th>\n",
       "      <th>tweet_token</th>\n",
       "      <th>tweet_token_filtered</th>\n",
       "      <th>tweet_stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "      <td>when father is dysfunctional and is so selfish...</td>\n",
       "      <td>[when, father, is, dysfunctional, and, is, so,...</td>\n",
       "      <td>[father, dysfunctional, selfish, drags, kids, ...</td>\n",
       "      <td>[father, dysfunct, selfish, drag, kid, dysfunc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "      <td>thanks for lyft credit cannot use cause they d...</td>\n",
       "      <td>[thanks, for, lyft, credit, can, not, use, cau...</td>\n",
       "      <td>[thanks, lyft, credit, use, cause, offer, whee...</td>\n",
       "      <td>[thank, lyft, credit, use, caus, offer, wheelc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>[bihday, your, majesty]</td>\n",
       "      <td>[bihday, majesty]</td>\n",
       "      <td>[bihday, majesti]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "      <td>model love you take with you all the time in your</td>\n",
       "      <td>[model, love, you, take, with, you, all, the, ...</td>\n",
       "      <td>[model, love, take, time]</td>\n",
       "      <td>[model, love, take, time]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "      <td>factsguide society now motivation</td>\n",
       "      <td>[factsguide, society, now, motivation]</td>\n",
       "      <td>[factsguide, society, motivation]</td>\n",
       "      <td>[factsguid, societi, motiv]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49154</td>\n",
       "      <td>49155</td>\n",
       "      <td>NaN</td>\n",
       "      <td>thought factory: left-right polarisation! #tru...</td>\n",
       "      <td>thought factory left right polarisation trump ...</td>\n",
       "      <td>[thought, factory, left, right, polarisation, ...</td>\n",
       "      <td>[thought, factory, left, right, polarisation, ...</td>\n",
       "      <td>[thought, factori, left, right, polaris, trump...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49155</td>\n",
       "      <td>49156</td>\n",
       "      <td>NaN</td>\n",
       "      <td>feeling like a mermaid ð #hairflip #neverre...</td>\n",
       "      <td>feeling like mermaid hairflip neverready forma...</td>\n",
       "      <td>[feeling, like, mermaid, hairflip, neverready,...</td>\n",
       "      <td>[feeling, like, mermaid, hairflip, neverready,...</td>\n",
       "      <td>[feel, like, mermaid, hairflip, neverreadi, fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49156</td>\n",
       "      <td>49157</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#hillary #campaigned today in #ohio((omg)) &amp;am...</td>\n",
       "      <td>hillary campaigned today in ohio omg used word...</td>\n",
       "      <td>[hillary, campaigned, today, in, ohio, omg, us...</td>\n",
       "      <td>[hillary, campaigned, today, ohio, omg, used, ...</td>\n",
       "      <td>[hillari, campaign, today, ohio, omg, use, wor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49157</td>\n",
       "      <td>49158</td>\n",
       "      <td>NaN</td>\n",
       "      <td>happy, at work conference: right mindset leads...</td>\n",
       "      <td>happy at work conference right mindset leads t...</td>\n",
       "      <td>[happy, at, work, conference, right, mindset, ...</td>\n",
       "      <td>[happy, work, conference, right, mindset, lead...</td>\n",
       "      <td>[happi, work, confer, right, mindset, lead, cu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49158</td>\n",
       "      <td>49159</td>\n",
       "      <td>NaN</td>\n",
       "      <td>my   song \"so glad\" free download!  #shoegaze ...</td>\n",
       "      <td>my song so glad free download shoegaze newmusi...</td>\n",
       "      <td>[my, song, so, glad, free, download, shoegaze,...</td>\n",
       "      <td>[song, glad, free, download, shoegaze, newmusi...</td>\n",
       "      <td>[song, glad, free, download, shoegaz, newmus, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49159 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  label                                              tweet  \\\n",
       "0          1    0.0   @user when a father is dysfunctional and is s...   \n",
       "1          2    0.0  @user @user thanks for #lyft credit i can't us...   \n",
       "2          3    0.0                                bihday your majesty   \n",
       "3          4    0.0  #model   i love u take with u all the time in ...   \n",
       "4          5    0.0             factsguide: society now    #motivation   \n",
       "...      ...    ...                                                ...   \n",
       "49154  49155    NaN  thought factory: left-right polarisation! #tru...   \n",
       "49155  49156    NaN  feeling like a mermaid ð #hairflip #neverre...   \n",
       "49156  49157    NaN  #hillary #campaigned today in #ohio((omg)) &am...   \n",
       "49157  49158    NaN  happy, at work conference: right mindset leads...   \n",
       "49158  49159    NaN  my   song \"so glad\" free download!  #shoegaze ...   \n",
       "\n",
       "                                             clear_tweet  \\\n",
       "0      when father is dysfunctional and is so selfish...   \n",
       "1      thanks for lyft credit cannot use cause they d...   \n",
       "2                                    bihday your majesty   \n",
       "3      model love you take with you all the time in your   \n",
       "4                      factsguide society now motivation   \n",
       "...                                                  ...   \n",
       "49154  thought factory left right polarisation trump ...   \n",
       "49155  feeling like mermaid hairflip neverready forma...   \n",
       "49156  hillary campaigned today in ohio omg used word...   \n",
       "49157  happy at work conference right mindset leads t...   \n",
       "49158  my song so glad free download shoegaze newmusi...   \n",
       "\n",
       "                                             tweet_token  \\\n",
       "0      [when, father, is, dysfunctional, and, is, so,...   \n",
       "1      [thanks, for, lyft, credit, can, not, use, cau...   \n",
       "2                                [bihday, your, majesty]   \n",
       "3      [model, love, you, take, with, you, all, the, ...   \n",
       "4                 [factsguide, society, now, motivation]   \n",
       "...                                                  ...   \n",
       "49154  [thought, factory, left, right, polarisation, ...   \n",
       "49155  [feeling, like, mermaid, hairflip, neverready,...   \n",
       "49156  [hillary, campaigned, today, in, ohio, omg, us...   \n",
       "49157  [happy, at, work, conference, right, mindset, ...   \n",
       "49158  [my, song, so, glad, free, download, shoegaze,...   \n",
       "\n",
       "                                    tweet_token_filtered  \\\n",
       "0      [father, dysfunctional, selfish, drags, kids, ...   \n",
       "1      [thanks, lyft, credit, use, cause, offer, whee...   \n",
       "2                                      [bihday, majesty]   \n",
       "3                              [model, love, take, time]   \n",
       "4                      [factsguide, society, motivation]   \n",
       "...                                                  ...   \n",
       "49154  [thought, factory, left, right, polarisation, ...   \n",
       "49155  [feeling, like, mermaid, hairflip, neverready,...   \n",
       "49156  [hillary, campaigned, today, ohio, omg, used, ...   \n",
       "49157  [happy, work, conference, right, mindset, lead...   \n",
       "49158  [song, glad, free, download, shoegaze, newmusi...   \n",
       "\n",
       "                                           tweet_stemmed  \n",
       "0      [father, dysfunct, selfish, drag, kid, dysfunc...  \n",
       "1      [thank, lyft, credit, use, caus, offer, wheelc...  \n",
       "2                                      [bihday, majesti]  \n",
       "3                              [model, love, take, time]  \n",
       "4                            [factsguid, societi, motiv]  \n",
       "...                                                  ...  \n",
       "49154  [thought, factori, left, right, polaris, trump...  \n",
       "49155  [feel, like, mermaid, hairflip, neverreadi, fo...  \n",
       "49156  [hillari, campaign, today, ohio, omg, use, wor...  \n",
       "49157  [happi, work, confer, right, mindset, lead, cu...  \n",
       "49158  [song, glad, free, download, shoegaz, newmus, ...  \n",
       "\n",
       "[49159 rows x 7 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combine_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14. Применим лемматизацию к токенам с помощью nltk.stem.wordnet.WordNetLemmatizer. Создадим столбец 'tweet_lemmatized' после применения лемматизации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\AKonshini\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatized_word_tokens(tweets):\n",
    "    clean_tweets=[]\n",
    "    lemmatizer=WordNetLemmatizer()\n",
    "    for tweet in tweets:\n",
    "        tweet=[lemmatizer.lemmatize(word, wordnet.VERB) for word  in tweet]\n",
    "        \n",
    "        clean_tweets.append(tweet)\n",
    "    return clean_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_df['tweet_lemmatized']=lemmatized_word_tokens(np.array(combine_df['tweet_token_filtered']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>clear_tweet</th>\n",
       "      <th>tweet_token</th>\n",
       "      <th>tweet_token_filtered</th>\n",
       "      <th>tweet_stemmed</th>\n",
       "      <th>tweet_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "      <td>when father is dysfunctional and is so selfish...</td>\n",
       "      <td>[when, father, is, dysfunctional, and, is, so,...</td>\n",
       "      <td>[father, dysfunctional, selfish, drags, kids, ...</td>\n",
       "      <td>[father, dysfunct, selfish, drag, kid, dysfunc...</td>\n",
       "      <td>[father, dysfunctional, selfish, drag, kid, dy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "      <td>thanks for lyft credit cannot use cause they d...</td>\n",
       "      <td>[thanks, for, lyft, credit, can, not, use, cau...</td>\n",
       "      <td>[thanks, lyft, credit, use, cause, offer, whee...</td>\n",
       "      <td>[thank, lyft, credit, use, caus, offer, wheelc...</td>\n",
       "      <td>[thank, lyft, credit, use, cause, offer, wheel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>[bihday, your, majesty]</td>\n",
       "      <td>[bihday, majesty]</td>\n",
       "      <td>[bihday, majesti]</td>\n",
       "      <td>[bihday, majesty]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "      <td>model love you take with you all the time in your</td>\n",
       "      <td>[model, love, you, take, with, you, all, the, ...</td>\n",
       "      <td>[model, love, take, time]</td>\n",
       "      <td>[model, love, take, time]</td>\n",
       "      <td>[model, love, take, time]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "      <td>factsguide society now motivation</td>\n",
       "      <td>[factsguide, society, now, motivation]</td>\n",
       "      <td>[factsguide, society, motivation]</td>\n",
       "      <td>[factsguid, societi, motiv]</td>\n",
       "      <td>[factsguide, society, motivation]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49154</td>\n",
       "      <td>49155</td>\n",
       "      <td>NaN</td>\n",
       "      <td>thought factory: left-right polarisation! #tru...</td>\n",
       "      <td>thought factory left right polarisation trump ...</td>\n",
       "      <td>[thought, factory, left, right, polarisation, ...</td>\n",
       "      <td>[thought, factory, left, right, polarisation, ...</td>\n",
       "      <td>[thought, factori, left, right, polaris, trump...</td>\n",
       "      <td>[think, factory, leave, right, polarisation, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49155</td>\n",
       "      <td>49156</td>\n",
       "      <td>NaN</td>\n",
       "      <td>feeling like a mermaid ð #hairflip #neverre...</td>\n",
       "      <td>feeling like mermaid hairflip neverready forma...</td>\n",
       "      <td>[feeling, like, mermaid, hairflip, neverready,...</td>\n",
       "      <td>[feeling, like, mermaid, hairflip, neverready,...</td>\n",
       "      <td>[feel, like, mermaid, hairflip, neverreadi, fo...</td>\n",
       "      <td>[feel, like, mermaid, hairflip, neverready, fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49156</td>\n",
       "      <td>49157</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#hillary #campaigned today in #ohio((omg)) &amp;am...</td>\n",
       "      <td>hillary campaigned today in ohio omg used word...</td>\n",
       "      <td>[hillary, campaigned, today, in, ohio, omg, us...</td>\n",
       "      <td>[hillary, campaigned, today, ohio, omg, used, ...</td>\n",
       "      <td>[hillari, campaign, today, ohio, omg, use, wor...</td>\n",
       "      <td>[hillary, campaign, today, ohio, omg, use, wor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49157</td>\n",
       "      <td>49158</td>\n",
       "      <td>NaN</td>\n",
       "      <td>happy, at work conference: right mindset leads...</td>\n",
       "      <td>happy at work conference right mindset leads t...</td>\n",
       "      <td>[happy, at, work, conference, right, mindset, ...</td>\n",
       "      <td>[happy, work, conference, right, mindset, lead...</td>\n",
       "      <td>[happi, work, confer, right, mindset, lead, cu...</td>\n",
       "      <td>[happy, work, conference, right, mindset, lead...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49158</td>\n",
       "      <td>49159</td>\n",
       "      <td>NaN</td>\n",
       "      <td>my   song \"so glad\" free download!  #shoegaze ...</td>\n",
       "      <td>my song so glad free download shoegaze newmusi...</td>\n",
       "      <td>[my, song, so, glad, free, download, shoegaze,...</td>\n",
       "      <td>[song, glad, free, download, shoegaze, newmusi...</td>\n",
       "      <td>[song, glad, free, download, shoegaz, newmus, ...</td>\n",
       "      <td>[song, glad, free, download, shoegaze, newmusi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49159 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  label                                              tweet  \\\n",
       "0          1    0.0   @user when a father is dysfunctional and is s...   \n",
       "1          2    0.0  @user @user thanks for #lyft credit i can't us...   \n",
       "2          3    0.0                                bihday your majesty   \n",
       "3          4    0.0  #model   i love u take with u all the time in ...   \n",
       "4          5    0.0             factsguide: society now    #motivation   \n",
       "...      ...    ...                                                ...   \n",
       "49154  49155    NaN  thought factory: left-right polarisation! #tru...   \n",
       "49155  49156    NaN  feeling like a mermaid ð #hairflip #neverre...   \n",
       "49156  49157    NaN  #hillary #campaigned today in #ohio((omg)) &am...   \n",
       "49157  49158    NaN  happy, at work conference: right mindset leads...   \n",
       "49158  49159    NaN  my   song \"so glad\" free download!  #shoegaze ...   \n",
       "\n",
       "                                             clear_tweet  \\\n",
       "0      when father is dysfunctional and is so selfish...   \n",
       "1      thanks for lyft credit cannot use cause they d...   \n",
       "2                                    bihday your majesty   \n",
       "3      model love you take with you all the time in your   \n",
       "4                      factsguide society now motivation   \n",
       "...                                                  ...   \n",
       "49154  thought factory left right polarisation trump ...   \n",
       "49155  feeling like mermaid hairflip neverready forma...   \n",
       "49156  hillary campaigned today in ohio omg used word...   \n",
       "49157  happy at work conference right mindset leads t...   \n",
       "49158  my song so glad free download shoegaze newmusi...   \n",
       "\n",
       "                                             tweet_token  \\\n",
       "0      [when, father, is, dysfunctional, and, is, so,...   \n",
       "1      [thanks, for, lyft, credit, can, not, use, cau...   \n",
       "2                                [bihday, your, majesty]   \n",
       "3      [model, love, you, take, with, you, all, the, ...   \n",
       "4                 [factsguide, society, now, motivation]   \n",
       "...                                                  ...   \n",
       "49154  [thought, factory, left, right, polarisation, ...   \n",
       "49155  [feeling, like, mermaid, hairflip, neverready,...   \n",
       "49156  [hillary, campaigned, today, in, ohio, omg, us...   \n",
       "49157  [happy, at, work, conference, right, mindset, ...   \n",
       "49158  [my, song, so, glad, free, download, shoegaze,...   \n",
       "\n",
       "                                    tweet_token_filtered  \\\n",
       "0      [father, dysfunctional, selfish, drags, kids, ...   \n",
       "1      [thanks, lyft, credit, use, cause, offer, whee...   \n",
       "2                                      [bihday, majesty]   \n",
       "3                              [model, love, take, time]   \n",
       "4                      [factsguide, society, motivation]   \n",
       "...                                                  ...   \n",
       "49154  [thought, factory, left, right, polarisation, ...   \n",
       "49155  [feeling, like, mermaid, hairflip, neverready,...   \n",
       "49156  [hillary, campaigned, today, ohio, omg, used, ...   \n",
       "49157  [happy, work, conference, right, mindset, lead...   \n",
       "49158  [song, glad, free, download, shoegaze, newmusi...   \n",
       "\n",
       "                                           tweet_stemmed  \\\n",
       "0      [father, dysfunct, selfish, drag, kid, dysfunc...   \n",
       "1      [thank, lyft, credit, use, caus, offer, wheelc...   \n",
       "2                                      [bihday, majesti]   \n",
       "3                              [model, love, take, time]   \n",
       "4                            [factsguid, societi, motiv]   \n",
       "...                                                  ...   \n",
       "49154  [thought, factori, left, right, polaris, trump...   \n",
       "49155  [feel, like, mermaid, hairflip, neverreadi, fo...   \n",
       "49156  [hillari, campaign, today, ohio, omg, use, wor...   \n",
       "49157  [happi, work, confer, right, mindset, lead, cu...   \n",
       "49158  [song, glad, free, download, shoegaz, newmus, ...   \n",
       "\n",
       "                                        tweet_lemmatized  \n",
       "0      [father, dysfunctional, selfish, drag, kid, dy...  \n",
       "1      [thank, lyft, credit, use, cause, offer, wheel...  \n",
       "2                                      [bihday, majesty]  \n",
       "3                              [model, love, take, time]  \n",
       "4                      [factsguide, society, motivation]  \n",
       "...                                                  ...  \n",
       "49154  [think, factory, leave, right, polarisation, t...  \n",
       "49155  [feel, like, mermaid, hairflip, neverready, fo...  \n",
       "49156  [hillary, campaign, today, ohio, omg, use, wor...  \n",
       "49157  [happy, work, conference, right, mindset, lead...  \n",
       "49158  [song, glad, free, download, shoegaze, newmusi...  \n",
       "\n",
       "[49159 rows x 8 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combine_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Создайте мешок слов с помощью sklearn.feature_extraction.text.CountVectorizer.fit_transform(). Применим его к 'tweet_stemmed' и 'tweet_lemmatized' отдельно.\n",
    "●\tИгнорируем слова, частота которых в документе строго превышает порог 0.9 с помощью max_df.\n",
    "●\tОграничим количество слов, попадающий в мешок, с помощью max_features = 1000.\n",
    "●\tИсключим стоп-слова с помощью stop_words='english'.\n",
    "●\tОтобразим Bag-of-Words модель как DataFrame. columns необходимо извлечь с помощью CountVectorizer.get_feature_names().\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(list):\n",
    "    return [','.join(x) for x in list]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_vectorizer=CountVectorizer(max_features=1000, max_df=0.9, stop_words='english')\n",
    "cv_ts=c_vectorizer.fit_transform(transform(combine_df['tweet_stemmed']))\n",
    "feature_names = c_vectorizer.get_feature_names()\n",
    "df_cv_ts=pd.DataFrame(cv_ts.toarray(), columns = feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abl</th>\n",
       "      <th>absolut</th>\n",
       "      <th>accept</th>\n",
       "      <th>account</th>\n",
       "      <th>act</th>\n",
       "      <th>action</th>\n",
       "      <th>actor</th>\n",
       "      <th>actual</th>\n",
       "      <th>ad</th>\n",
       "      <th>adapt</th>\n",
       "      <th>...</th>\n",
       "      <th>year</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>yo</th>\n",
       "      <th>yoga</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>youtub</th>\n",
       "      <th>yoyou</th>\n",
       "      <th>yr</th>\n",
       "      <th>yummi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49154</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49155</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49156</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49157</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49158</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49159 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       abl  absolut  accept  account  act  action  actor  actual  ad  adapt  \\\n",
       "0        0        0       0        0    0       0      0       0   0      0   \n",
       "1        0        0       0        0    0       0      0       0   0      0   \n",
       "2        0        0       0        0    0       0      0       0   0      0   \n",
       "3        0        0       0        0    0       0      0       0   0      0   \n",
       "4        0        0       0        0    0       0      0       0   0      0   \n",
       "...    ...      ...     ...      ...  ...     ...    ...     ...  ..    ...   \n",
       "49154    0        0       0        0    0       0      0       0   0      0   \n",
       "49155    0        0       0        0    0       0      0       0   0      0   \n",
       "49156    0        0       0        0    0       0      0       0   0      0   \n",
       "49157    0        0       0        0    0       0      0       0   0      0   \n",
       "49158    0        0       0        0    0       0      0       0   0      0   \n",
       "\n",
       "       ...  year  yesterday  yo  yoga  york  young  youtub  yoyou  yr  yummi  \n",
       "0      ...     0          0   0     0     0      0       0      0   0      0  \n",
       "1      ...     0          0   0     0     0      0       0      0   0      0  \n",
       "2      ...     0          0   0     0     0      0       0      0   0      0  \n",
       "3      ...     0          0   0     0     0      0       0      0   0      0  \n",
       "4      ...     0          0   0     0     0      0       0      0   0      0  \n",
       "...    ...   ...        ...  ..   ...   ...    ...     ...    ...  ..    ...  \n",
       "49154  ...     0          0   0     0     0      0       0      0   0      0  \n",
       "49155  ...     0          0   0     0     0      0       0      0   0      0  \n",
       "49156  ...     0          0   0     0     0      0       0      0   0      0  \n",
       "49157  ...     0          0   0     0     0      0       0      0   0      0  \n",
       "49158  ...     0          0   0     0     0      0       0      0   0      0  \n",
       "\n",
       "[49159 rows x 1000 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cv_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_vectorizer_1=CountVectorizer(max_features=1000, max_df=0.9, stop_words='english')\n",
    "cv_tl=c_vectorizer_1.fit_transform(transform(combine_df['tweet_lemmatized']))\n",
    "feature_names = c_vectorizer_1.get_feature_names()\n",
    "df_cv_tl=pd.DataFrame(cv_tl.toarray(), columns = feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>able</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>accept</th>\n",
       "      <th>account</th>\n",
       "      <th>act</th>\n",
       "      <th>action</th>\n",
       "      <th>actor</th>\n",
       "      <th>actually</th>\n",
       "      <th>adapt</th>\n",
       "      <th>add</th>\n",
       "      <th>...</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>yo</th>\n",
       "      <th>yoga</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>youtube</th>\n",
       "      <th>yoyou</th>\n",
       "      <th>yr</th>\n",
       "      <th>yrs</th>\n",
       "      <th>yummy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49154</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49155</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49156</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49157</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49158</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49159 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       able  absolutely  accept  account  act  action  actor  actually  adapt  \\\n",
       "0         0           0       0        0    0       0      0         0      0   \n",
       "1         0           0       0        0    0       0      0         0      0   \n",
       "2         0           0       0        0    0       0      0         0      0   \n",
       "3         0           0       0        0    0       0      0         0      0   \n",
       "4         0           0       0        0    0       0      0         0      0   \n",
       "...     ...         ...     ...      ...  ...     ...    ...       ...    ...   \n",
       "49154     0           0       0        0    0       0      0         0      0   \n",
       "49155     0           0       0        0    0       0      0         0      0   \n",
       "49156     0           0       0        0    0       0      0         0      0   \n",
       "49157     0           0       0        0    0       0      0         0      0   \n",
       "49158     0           0       0        0    0       0      0         0      0   \n",
       "\n",
       "       add  ...  yesterday  yo  yoga  york  young  youtube  yoyou  yr  yrs  \\\n",
       "0        0  ...          0   0     0     0      0        0      0   0    0   \n",
       "1        0  ...          0   0     0     0      0        0      0   0    0   \n",
       "2        0  ...          0   0     0     0      0        0      0   0    0   \n",
       "3        0  ...          0   0     0     0      0        0      0   0    0   \n",
       "4        0  ...          0   0     0     0      0        0      0   0    0   \n",
       "...    ...  ...        ...  ..   ...   ...    ...      ...    ...  ..  ...   \n",
       "49154    0  ...          0   0     0     0      0        0      0   0    0   \n",
       "49155    0  ...          0   0     0     0      0        0      0   0    0   \n",
       "49156    0  ...          0   0     0     0      0        0      0   0    0   \n",
       "49157    0  ...          0   0     0     0      0        0      0   0    0   \n",
       "49158    0  ...          0   0     0     0      0        0      0   0    0   \n",
       "\n",
       "       yummy  \n",
       "0          0  \n",
       "1          0  \n",
       "2          0  \n",
       "3          0  \n",
       "4          0  \n",
       "...      ...  \n",
       "49154      0  \n",
       "49155      0  \n",
       "49156      0  \n",
       "49157      0  \n",
       "49158      0  \n",
       "\n",
       "[49159 rows x 1000 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cv_tl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ". Создайте мешок слов с помощью sklearn.feature_extraction.text.TfidfVectorizer.fit_transform(). Применим его к 'tweet_stemmed' и 'tweet_lemmatized' отдельно.\n",
    "●\tИгнорируем слова, частота которых в документе строго превышает порог 0.9 с помощью max_df.\n",
    "●\tОграничим количество слов, попадающий в мешок, с помощью max_features = 1000.\n",
    "●\tИсключим стоп-слова с помощью stop_words='english'.\n",
    "●\tОтобразим Bag-of-Words модель как DataFrame. columns необходимо извлечь с помощью TfidfVectorizer.get_feature_names().\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfid_vectorizer=TfidfVectorizer(max_features=1000, max_df=0.9, stop_words='english')\n",
    "tv_ts=tfid_vectorizer.fit_transform(transform(combine_df['tweet_stemmed']))\n",
    "feature_names = tfid_vectorizer.get_feature_names()\n",
    "df_tv_ts=pd.DataFrame(tv_ts.toarray(), columns = feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abl</th>\n",
       "      <th>absolut</th>\n",
       "      <th>accept</th>\n",
       "      <th>account</th>\n",
       "      <th>act</th>\n",
       "      <th>action</th>\n",
       "      <th>activ</th>\n",
       "      <th>actor</th>\n",
       "      <th>actual</th>\n",
       "      <th>ad</th>\n",
       "      <th>...</th>\n",
       "      <th>year</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>yo</th>\n",
       "      <th>yoga</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>youtub</th>\n",
       "      <th>yoyou</th>\n",
       "      <th>yr</th>\n",
       "      <th>yummi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49154</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49155</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49156</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49157</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49158</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49159 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       abl  absolut  accept  account  act  action  activ  actor  actual   ad  \\\n",
       "0      0.0      0.0     0.0      0.0  0.0     0.0    0.0    0.0     0.0  0.0   \n",
       "1      0.0      0.0     0.0      0.0  0.0     0.0    0.0    0.0     0.0  0.0   \n",
       "2      0.0      0.0     0.0      0.0  0.0     0.0    0.0    0.0     0.0  0.0   \n",
       "3      0.0      0.0     0.0      0.0  0.0     0.0    0.0    0.0     0.0  0.0   \n",
       "4      0.0      0.0     0.0      0.0  0.0     0.0    0.0    0.0     0.0  0.0   \n",
       "...    ...      ...     ...      ...  ...     ...    ...    ...     ...  ...   \n",
       "49154  0.0      0.0     0.0      0.0  0.0     0.0    0.0    0.0     0.0  0.0   \n",
       "49155  0.0      0.0     0.0      0.0  0.0     0.0    0.0    0.0     0.0  0.0   \n",
       "49156  0.0      0.0     0.0      0.0  0.0     0.0    0.0    0.0     0.0  0.0   \n",
       "49157  0.0      0.0     0.0      0.0  0.0     0.0    0.0    0.0     0.0  0.0   \n",
       "49158  0.0      0.0     0.0      0.0  0.0     0.0    0.0    0.0     0.0  0.0   \n",
       "\n",
       "       ...  year  yesterday   yo  yoga  york  young  youtub  yoyou   yr  yummi  \n",
       "0      ...   0.0        0.0  0.0   0.0   0.0    0.0     0.0    0.0  0.0    0.0  \n",
       "1      ...   0.0        0.0  0.0   0.0   0.0    0.0     0.0    0.0  0.0    0.0  \n",
       "2      ...   0.0        0.0  0.0   0.0   0.0    0.0     0.0    0.0  0.0    0.0  \n",
       "3      ...   0.0        0.0  0.0   0.0   0.0    0.0     0.0    0.0  0.0    0.0  \n",
       "4      ...   0.0        0.0  0.0   0.0   0.0    0.0     0.0    0.0  0.0    0.0  \n",
       "...    ...   ...        ...  ...   ...   ...    ...     ...    ...  ...    ...  \n",
       "49154  ...   0.0        0.0  0.0   0.0   0.0    0.0     0.0    0.0  0.0    0.0  \n",
       "49155  ...   0.0        0.0  0.0   0.0   0.0    0.0     0.0    0.0  0.0    0.0  \n",
       "49156  ...   0.0        0.0  0.0   0.0   0.0    0.0     0.0    0.0  0.0    0.0  \n",
       "49157  ...   0.0        0.0  0.0   0.0   0.0    0.0     0.0    0.0  0.0    0.0  \n",
       "49158  ...   0.0        0.0  0.0   0.0   0.0    0.0     0.0    0.0  0.0    0.0  \n",
       "\n",
       "[49159 rows x 1000 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tv_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfid_vectorizer_1=TfidfVectorizer(max_features=1000, max_df=0.9, stop_words='english')\n",
    "tv_tl=tfid_vectorizer_1.fit_transform(transform(combine_df['tweet_stemmed']))\n",
    "feature_names = tfid_vectorizer_1.get_feature_names()\n",
    "df_tv_tl=pd.DataFrame(tv_tl.toarray(), columns = feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abl</th>\n",
       "      <th>absolut</th>\n",
       "      <th>accept</th>\n",
       "      <th>account</th>\n",
       "      <th>act</th>\n",
       "      <th>action</th>\n",
       "      <th>activ</th>\n",
       "      <th>actor</th>\n",
       "      <th>actual</th>\n",
       "      <th>ad</th>\n",
       "      <th>...</th>\n",
       "      <th>year</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>yo</th>\n",
       "      <th>yoga</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>youtub</th>\n",
       "      <th>yoyou</th>\n",
       "      <th>yr</th>\n",
       "      <th>yummi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49154</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49155</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49156</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49157</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49158</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49159 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       abl  absolut  accept  account  act  action  activ  actor  actual   ad  \\\n",
       "0      0.0      0.0     0.0      0.0  0.0     0.0    0.0    0.0     0.0  0.0   \n",
       "1      0.0      0.0     0.0      0.0  0.0     0.0    0.0    0.0     0.0  0.0   \n",
       "2      0.0      0.0     0.0      0.0  0.0     0.0    0.0    0.0     0.0  0.0   \n",
       "3      0.0      0.0     0.0      0.0  0.0     0.0    0.0    0.0     0.0  0.0   \n",
       "4      0.0      0.0     0.0      0.0  0.0     0.0    0.0    0.0     0.0  0.0   \n",
       "...    ...      ...     ...      ...  ...     ...    ...    ...     ...  ...   \n",
       "49154  0.0      0.0     0.0      0.0  0.0     0.0    0.0    0.0     0.0  0.0   \n",
       "49155  0.0      0.0     0.0      0.0  0.0     0.0    0.0    0.0     0.0  0.0   \n",
       "49156  0.0      0.0     0.0      0.0  0.0     0.0    0.0    0.0     0.0  0.0   \n",
       "49157  0.0      0.0     0.0      0.0  0.0     0.0    0.0    0.0     0.0  0.0   \n",
       "49158  0.0      0.0     0.0      0.0  0.0     0.0    0.0    0.0     0.0  0.0   \n",
       "\n",
       "       ...  year  yesterday   yo  yoga  york  young  youtub  yoyou   yr  yummi  \n",
       "0      ...   0.0        0.0  0.0   0.0   0.0    0.0     0.0    0.0  0.0    0.0  \n",
       "1      ...   0.0        0.0  0.0   0.0   0.0    0.0     0.0    0.0  0.0    0.0  \n",
       "2      ...   0.0        0.0  0.0   0.0   0.0    0.0     0.0    0.0  0.0    0.0  \n",
       "3      ...   0.0        0.0  0.0   0.0   0.0    0.0     0.0    0.0  0.0    0.0  \n",
       "4      ...   0.0        0.0  0.0   0.0   0.0    0.0     0.0    0.0  0.0    0.0  \n",
       "...    ...   ...        ...  ...   ...   ...    ...     ...    ...  ...    ...  \n",
       "49154  ...   0.0        0.0  0.0   0.0   0.0    0.0     0.0    0.0  0.0    0.0  \n",
       "49155  ...   0.0        0.0  0.0   0.0   0.0    0.0     0.0    0.0  0.0    0.0  \n",
       "49156  ...   0.0        0.0  0.0   0.0   0.0    0.0     0.0    0.0  0.0    0.0  \n",
       "49157  ...   0.0        0.0  0.0   0.0   0.0    0.0     0.0    0.0  0.0    0.0  \n",
       "49158  ...   0.0        0.0  0.0   0.0   0.0    0.0     0.0    0.0  0.0    0.0  \n",
       "\n",
       "[49159 rows x 1000 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tv_tl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Натренируем gensim.models.Word2Vec модель на наших данных.\n",
    "●\tТренировать будем на токенизированных твитах combine_df['tweet_token']\n",
    "●\tУстановим следующие параметры: size=200, window=5, min_count=2, sg = 1, hs = 0, negative = 10, workers= 32, seed = 34.\n",
    "●\tИспользуем функцию train() с параметром total_examples равным длине combine_df['tweet_token'], количество epochs установим 20.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python -m pip install -U gensim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import common_texts, get_tmpfile\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['human', 'interface', 'computer'],\n",
       " ['survey', 'user', 'computer', 'system', 'response', 'time'],\n",
       " ['eps', 'user', 'interface', 'system'],\n",
       " ['system', 'human', 'system', 'eps'],\n",
       " ['user', 'response', 'time'],\n",
       " ['trees'],\n",
       " ['graph', 'trees'],\n",
       " ['graph', 'minors', 'trees'],\n",
       " ['graph', 'minors', 'survey']]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9779716, 11728980)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Word2Vec(combine_df['tweet_token'], size=200, window=5, min_count=1, sg = 1, hs = 0, negative = 10, workers= 32, seed = 34)\n",
    "model.train(combine_df['tweet_token'], total_examples=len(combine_df['tweet_token']), epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('cookout', 0.564275860786438),\n",
       " ('tacotuesday', 0.5589213371276855),\n",
       " ('bolognese', 0.5550484657287598),\n",
       " ('spaghetti', 0.5538142323493958),\n",
       " ('thegafford', 0.5421160459518433),\n",
       " ('saturdate', 0.5414692163467407),\n",
       " ('bihdaydinner', 0.54052734375),\n",
       " ('eastvillage', 0.5353958010673523),\n",
       " ('fixings', 0.5348232388496399),\n",
       " ('nighout', 0.5336989164352417)]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = model.most_similar(positive='dinner')\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('donald', 0.6120071411132812),\n",
       " ('donaldtrump', 0.58404141664505),\n",
       " ('conman', 0.5485681295394897),\n",
       " ('carl', 0.5474090576171875),\n",
       " ('trumptrain', 0.5473381280899048),\n",
       " ('dumptrump', 0.5464363098144531),\n",
       " ('suppoer', 0.5425091981887817),\n",
       " ('crony', 0.5400735139846802),\n",
       " ('chopra', 0.5366895198822021),\n",
       " ('unfavorability', 0.5355014801025391)]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = model.most_similar(positive='trump')\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.67829543, -0.03694221,  0.40075308, -0.17823602, -0.00598903,\n",
       "       -0.29507938, -0.15119854,  0.1618732 ,  0.07436924,  0.280707  ,\n",
       "        0.10015264, -0.03730475, -0.3090114 ,  0.39807466, -0.12523724,\n",
       "        0.65055317, -0.02594494, -0.60992104, -0.6502828 , -0.8738919 ,\n",
       "        0.61222774,  0.12920502, -0.37057504,  0.6449006 , -0.05576085,\n",
       "       -0.4488338 ,  0.47409979, -0.08937211,  1.0699109 ,  0.03194651,\n",
       "       -0.14387691, -0.45818207, -0.47153288, -0.19933678, -0.40389025,\n",
       "       -0.27586204,  0.00315385,  0.3833242 , -0.04159053,  0.2565722 ,\n",
       "        0.3277087 ,  0.16312999, -0.19084433, -0.00127277,  0.26012862,\n",
       "       -0.07238272, -0.46536958, -0.17530303,  0.05117337, -0.1596858 ,\n",
       "       -0.03439998, -0.34022784, -0.28993946, -0.04210832, -0.17710039,\n",
       "        0.08291996, -0.07395516,  0.22006929,  0.24349472,  0.47884297,\n",
       "        0.11523283,  0.04325754, -0.2824674 ,  0.13134472,  0.26364756,\n",
       "        0.17773183,  1.066976  ,  0.6837736 ,  0.11797065,  0.22464041,\n",
       "        0.766967  ,  1.0717509 , -0.27225938,  0.4447903 ,  0.01971915,\n",
       "       -0.45753273, -0.4901413 ,  0.583562  ,  0.20802963, -0.77753896,\n",
       "        0.3179466 , -0.04606801,  0.07855843,  0.5760957 ,  0.09452629,\n",
       "       -0.61812437,  0.74155384, -0.5312402 ,  0.46089646, -0.4367245 ,\n",
       "       -0.10587557,  0.7486867 ,  0.11110038,  0.5500872 , -0.25281313,\n",
       "       -0.10244992,  0.20268588,  0.1163199 , -0.28275752, -0.3423943 ,\n",
       "       -0.34477982, -0.02996499,  0.17369477, -0.03251392, -0.25776008,\n",
       "        0.2338181 ,  0.31980154, -0.2909497 , -0.17384315,  0.34901044,\n",
       "       -0.39553192, -0.08129403, -0.8622    , -0.10702021,  0.03102968,\n",
       "       -0.05200455, -0.38083586,  0.43135887,  0.6165474 , -0.15706602,\n",
       "        0.29130888,  0.16457735,  0.3031295 , -0.56264853, -0.08886413,\n",
       "        0.32667327,  0.37894887,  0.20520833, -0.66543883, -0.05261729,\n",
       "        0.41752326, -0.84157246,  0.33809897, -0.0352384 ,  0.46238652,\n",
       "        0.36916876,  0.26071125, -0.1148906 ,  0.4569424 , -0.1606892 ,\n",
       "        0.23627499,  0.22999631,  0.17831995,  0.5932245 , -0.24922931,\n",
       "       -0.51595336,  0.10211321,  0.33831868, -0.40820244,  0.7685002 ,\n",
       "       -0.2318405 , -0.09963746,  0.55070037, -0.43471462,  0.18332662,\n",
       "        0.25570798, -0.17703885, -0.10712994,  0.14295705, -0.4792982 ,\n",
       "        0.72990817, -0.37536848,  0.10350061, -0.2680761 ,  0.595118  ,\n",
       "        0.4461947 ,  0.5332153 , -0.5408578 ,  0.6104007 ,  0.1882169 ,\n",
       "        0.32036626,  0.38582632,  0.01496803, -0.09898907,  0.01824286,\n",
       "        0.36102563,  0.04629778, -0.12340809,  0.01657489, -0.01017223,\n",
       "        0.3437926 ,  0.08469786,  0.00430108, -0.11698179,  0.63743484,\n",
       "        0.18905629, -0.18936408,  0.4338704 , -0.07571819,  0.4550077 ,\n",
       "       -0.24863495, -0.28391173, -0.07682525, -0.2463692 , -0.5161491 ,\n",
       "        0.31429103, -1.1185242 ,  0.04360604, -0.47217083, -0.17785129],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector = model.wv['when'] \n",
    "vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поскольку наши данные содержат твиты, а не только слова, нам придется придумать способ использовать векторы слов из модели word2vec для создания векторного представления всего твита. Существует простое решение этой проблемы, мы можем просто взять среднее значение всех векторов слов, присутствующих в твите. Длина результирующего вектора будет одинаковой, то есть 200. Мы повторим тот же процесс для всех твитов в наших данных и получим их векторы. Теперь у нас есть 200 функций word2vec для наших данных.\n",
    "Необходимо создать вектор для каждого твита, взяв среднее значение векторов слов, присутствующих в твите. В цикле сделать:  vec += model_w2v[word].reshape((1, size))\n",
    "и поделить финальный вектор на количество слов в твите.\n",
    "На выходе должен получиться wordvec_df.shape = (49159, 200).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_vecs=[]\n",
    "for tweet in np.array(combine_df['tweet_token']):\n",
    "    vec=np.zeros((1,200))\n",
    "    for word in tweet:\n",
    "        #print(word)\n",
    "        vec+=model[word].reshape((1, 200))\n",
    "    tweet_vecs.append(vec)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordvec_df=pd.DataFrame(np.array(tweet_vecs).reshape((49159, 200)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>190</th>\n",
       "      <th>191</th>\n",
       "      <th>192</th>\n",
       "      <th>193</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.072514</td>\n",
       "      <td>-7.240419</td>\n",
       "      <td>3.735607</td>\n",
       "      <td>0.334691</td>\n",
       "      <td>-4.444275</td>\n",
       "      <td>1.411898</td>\n",
       "      <td>-1.333478</td>\n",
       "      <td>-1.337524</td>\n",
       "      <td>3.599625</td>\n",
       "      <td>0.456294</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.360948</td>\n",
       "      <td>-1.018230</td>\n",
       "      <td>1.242321</td>\n",
       "      <td>0.775998</td>\n",
       "      <td>-1.001709</td>\n",
       "      <td>-3.429247</td>\n",
       "      <td>-4.455748</td>\n",
       "      <td>1.226732</td>\n",
       "      <td>2.567751</td>\n",
       "      <td>-5.606457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.523457</td>\n",
       "      <td>-6.353235</td>\n",
       "      <td>-0.143658</td>\n",
       "      <td>-0.067103</td>\n",
       "      <td>-4.599801</td>\n",
       "      <td>-2.371041</td>\n",
       "      <td>-2.398336</td>\n",
       "      <td>-1.485485</td>\n",
       "      <td>1.586563</td>\n",
       "      <td>0.453085</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.099446</td>\n",
       "      <td>-2.395812</td>\n",
       "      <td>-0.162872</td>\n",
       "      <td>0.709369</td>\n",
       "      <td>3.556373</td>\n",
       "      <td>-0.477198</td>\n",
       "      <td>-6.030418</td>\n",
       "      <td>2.846084</td>\n",
       "      <td>1.496731</td>\n",
       "      <td>-3.340926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.364791</td>\n",
       "      <td>-1.596203</td>\n",
       "      <td>0.146800</td>\n",
       "      <td>0.456262</td>\n",
       "      <td>-0.109230</td>\n",
       "      <td>-0.304634</td>\n",
       "      <td>0.915048</td>\n",
       "      <td>0.240053</td>\n",
       "      <td>0.630445</td>\n",
       "      <td>0.571648</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.493414</td>\n",
       "      <td>-0.791048</td>\n",
       "      <td>-1.754309</td>\n",
       "      <td>0.164862</td>\n",
       "      <td>-0.466531</td>\n",
       "      <td>-0.059635</td>\n",
       "      <td>0.515698</td>\n",
       "      <td>1.773079</td>\n",
       "      <td>0.031728</td>\n",
       "      <td>-2.000619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.287064</td>\n",
       "      <td>-2.921054</td>\n",
       "      <td>1.450517</td>\n",
       "      <td>1.195430</td>\n",
       "      <td>-3.395806</td>\n",
       "      <td>-2.039543</td>\n",
       "      <td>1.001645</td>\n",
       "      <td>0.557205</td>\n",
       "      <td>1.491542</td>\n",
       "      <td>0.336931</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.492186</td>\n",
       "      <td>-4.086902</td>\n",
       "      <td>-0.819071</td>\n",
       "      <td>0.880817</td>\n",
       "      <td>0.544602</td>\n",
       "      <td>-1.709614</td>\n",
       "      <td>-1.702999</td>\n",
       "      <td>2.449992</td>\n",
       "      <td>0.242835</td>\n",
       "      <td>-3.746835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>-0.240080</td>\n",
       "      <td>-1.253964</td>\n",
       "      <td>-0.523712</td>\n",
       "      <td>-0.864548</td>\n",
       "      <td>-0.629244</td>\n",
       "      <td>0.241647</td>\n",
       "      <td>-0.067872</td>\n",
       "      <td>-0.035628</td>\n",
       "      <td>0.678063</td>\n",
       "      <td>-0.583473</td>\n",
       "      <td>...</td>\n",
       "      <td>0.418457</td>\n",
       "      <td>0.155302</td>\n",
       "      <td>1.855362</td>\n",
       "      <td>0.793690</td>\n",
       "      <td>0.423226</td>\n",
       "      <td>-2.257488</td>\n",
       "      <td>-2.338315</td>\n",
       "      <td>0.020753</td>\n",
       "      <td>-0.190886</td>\n",
       "      <td>-1.251982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49154</td>\n",
       "      <td>0.103010</td>\n",
       "      <td>-4.527228</td>\n",
       "      <td>2.754126</td>\n",
       "      <td>3.840476</td>\n",
       "      <td>-8.927949</td>\n",
       "      <td>-0.380807</td>\n",
       "      <td>-4.693909</td>\n",
       "      <td>3.049116</td>\n",
       "      <td>-1.745026</td>\n",
       "      <td>-2.460687</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.694114</td>\n",
       "      <td>0.773355</td>\n",
       "      <td>-1.534455</td>\n",
       "      <td>-0.287546</td>\n",
       "      <td>1.451223</td>\n",
       "      <td>-10.624326</td>\n",
       "      <td>-5.508704</td>\n",
       "      <td>-0.943127</td>\n",
       "      <td>2.563089</td>\n",
       "      <td>-3.648403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49155</td>\n",
       "      <td>-0.202279</td>\n",
       "      <td>-3.776050</td>\n",
       "      <td>-0.855924</td>\n",
       "      <td>-0.681884</td>\n",
       "      <td>-2.738986</td>\n",
       "      <td>-1.409778</td>\n",
       "      <td>0.991225</td>\n",
       "      <td>-0.055392</td>\n",
       "      <td>0.548472</td>\n",
       "      <td>3.618258</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.743365</td>\n",
       "      <td>-2.663486</td>\n",
       "      <td>0.139315</td>\n",
       "      <td>2.020547</td>\n",
       "      <td>-1.678673</td>\n",
       "      <td>-0.995539</td>\n",
       "      <td>-1.527042</td>\n",
       "      <td>0.750088</td>\n",
       "      <td>0.437838</td>\n",
       "      <td>-3.391618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49156</td>\n",
       "      <td>-0.301327</td>\n",
       "      <td>-6.954018</td>\n",
       "      <td>-3.106408</td>\n",
       "      <td>-0.905063</td>\n",
       "      <td>-6.266304</td>\n",
       "      <td>-2.407467</td>\n",
       "      <td>-4.098484</td>\n",
       "      <td>-3.738306</td>\n",
       "      <td>0.099525</td>\n",
       "      <td>1.157665</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.937131</td>\n",
       "      <td>-4.732186</td>\n",
       "      <td>-0.101919</td>\n",
       "      <td>-1.793640</td>\n",
       "      <td>-0.351653</td>\n",
       "      <td>-2.785132</td>\n",
       "      <td>-6.415690</td>\n",
       "      <td>2.499205</td>\n",
       "      <td>2.122782</td>\n",
       "      <td>-1.146214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49157</td>\n",
       "      <td>1.326164</td>\n",
       "      <td>-2.061218</td>\n",
       "      <td>-0.446676</td>\n",
       "      <td>0.893642</td>\n",
       "      <td>-6.933105</td>\n",
       "      <td>-3.519839</td>\n",
       "      <td>-2.341351</td>\n",
       "      <td>3.959188</td>\n",
       "      <td>-3.085175</td>\n",
       "      <td>-2.575109</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.226994</td>\n",
       "      <td>0.374804</td>\n",
       "      <td>-2.292496</td>\n",
       "      <td>2.955901</td>\n",
       "      <td>-0.010156</td>\n",
       "      <td>-3.612312</td>\n",
       "      <td>-8.292209</td>\n",
       "      <td>-0.549390</td>\n",
       "      <td>6.311618</td>\n",
       "      <td>-2.672872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49158</td>\n",
       "      <td>1.763187</td>\n",
       "      <td>-2.611146</td>\n",
       "      <td>2.504903</td>\n",
       "      <td>-0.438556</td>\n",
       "      <td>-3.749186</td>\n",
       "      <td>-1.443444</td>\n",
       "      <td>-1.261869</td>\n",
       "      <td>-1.689354</td>\n",
       "      <td>0.557512</td>\n",
       "      <td>-0.355646</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.894407</td>\n",
       "      <td>1.012756</td>\n",
       "      <td>-0.938572</td>\n",
       "      <td>-0.365679</td>\n",
       "      <td>0.195432</td>\n",
       "      <td>-1.612716</td>\n",
       "      <td>-0.488472</td>\n",
       "      <td>0.562769</td>\n",
       "      <td>1.401934</td>\n",
       "      <td>-0.983970</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49159 rows × 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6    \\\n",
       "0      2.072514 -7.240419  3.735607  0.334691 -4.444275  1.411898 -1.333478   \n",
       "1      1.523457 -6.353235 -0.143658 -0.067103 -4.599801 -2.371041 -2.398336   \n",
       "2      1.364791 -1.596203  0.146800  0.456262 -0.109230 -0.304634  0.915048   \n",
       "3      4.287064 -2.921054  1.450517  1.195430 -3.395806 -2.039543  1.001645   \n",
       "4     -0.240080 -1.253964 -0.523712 -0.864548 -0.629244  0.241647 -0.067872   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "49154  0.103010 -4.527228  2.754126  3.840476 -8.927949 -0.380807 -4.693909   \n",
       "49155 -0.202279 -3.776050 -0.855924 -0.681884 -2.738986 -1.409778  0.991225   \n",
       "49156 -0.301327 -6.954018 -3.106408 -0.905063 -6.266304 -2.407467 -4.098484   \n",
       "49157  1.326164 -2.061218 -0.446676  0.893642 -6.933105 -3.519839 -2.341351   \n",
       "49158  1.763187 -2.611146  2.504903 -0.438556 -3.749186 -1.443444 -1.261869   \n",
       "\n",
       "            7         8         9    ...       190       191       192  \\\n",
       "0     -1.337524  3.599625  0.456294  ... -2.360948 -1.018230  1.242321   \n",
       "1     -1.485485  1.586563  0.453085  ... -1.099446 -2.395812 -0.162872   \n",
       "2      0.240053  0.630445  0.571648  ... -1.493414 -0.791048 -1.754309   \n",
       "3      0.557205  1.491542  0.336931  ... -2.492186 -4.086902 -0.819071   \n",
       "4     -0.035628  0.678063 -0.583473  ...  0.418457  0.155302  1.855362   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "49154  3.049116 -1.745026 -2.460687  ... -3.694114  0.773355 -1.534455   \n",
       "49155 -0.055392  0.548472  3.618258  ... -0.743365 -2.663486  0.139315   \n",
       "49156 -3.738306  0.099525  1.157665  ... -2.937131 -4.732186 -0.101919   \n",
       "49157  3.959188 -3.085175 -2.575109  ... -2.226994  0.374804 -2.292496   \n",
       "49158 -1.689354  0.557512 -0.355646  ... -1.894407  1.012756 -0.938572   \n",
       "\n",
       "            193       194        195       196       197       198       199  \n",
       "0      0.775998 -1.001709  -3.429247 -4.455748  1.226732  2.567751 -5.606457  \n",
       "1      0.709369  3.556373  -0.477198 -6.030418  2.846084  1.496731 -3.340926  \n",
       "2      0.164862 -0.466531  -0.059635  0.515698  1.773079  0.031728 -2.000619  \n",
       "3      0.880817  0.544602  -1.709614 -1.702999  2.449992  0.242835 -3.746835  \n",
       "4      0.793690  0.423226  -2.257488 -2.338315  0.020753 -0.190886 -1.251982  \n",
       "...         ...       ...        ...       ...       ...       ...       ...  \n",
       "49154 -0.287546  1.451223 -10.624326 -5.508704 -0.943127  2.563089 -3.648403  \n",
       "49155  2.020547 -1.678673  -0.995539 -1.527042  0.750088  0.437838 -3.391618  \n",
       "49156 -1.793640 -0.351653  -2.785132 -6.415690  2.499205  2.122782 -1.146214  \n",
       "49157  2.955901 -0.010156  -3.612312 -8.292209 -0.549390  6.311618 -2.672872  \n",
       "49158 -0.365679  0.195432  -1.612716 -0.488472  0.562769  1.401934 -0.983970  \n",
       "\n",
       "[49159 rows x 200 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordvec_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

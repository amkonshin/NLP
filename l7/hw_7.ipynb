{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "AttentionTransformerRus.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJAvIECN_VOU"
      },
      "source": [
        "# В предыдущей серии\n",
        "\n",
        "\n",
        "<img src=\"images/RNNCompar.png\"/>\n",
        "\n",
        "\n",
        "Мы посмотрели на задачу классификации текстов. Но есть ряд более сильных подходов, которые лучше показывать через задачу генерации\n",
        "\n",
        "\n",
        "# Генерация текстов, encoder-decoder\n",
        "\n",
        "<img src=\"images/EncDec.png\"/>\n",
        "\n",
        "\n",
        "Данная архитектура называется seq2seq, простыми словами выглядит она следующим образом:\n",
        "<img src=\"images/seq2seq.png\"/>\n",
        "\n",
        "\n",
        "эту модель можно строить на уровне слов и на уровне токенов. Попробуем обучить на уровне токенов"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2NCpUB1_VOW"
      },
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input, LSTM, Dense\n",
        "import numpy as np\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eluPzgSi_VOd"
      },
      "source": [
        "batch_size = 64\n",
        "epochs = 30\n",
        "latent_dim = 256\n",
        "num_samples = 10000\n",
        "data_path = 'rus.txt'"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "317Tr0e-_VOh"
      },
      "source": [
        "# Собираем из текстов токены и делаем pne-hot вектора на каждый токен\n",
        "\n",
        "input_texts = []\n",
        "target_texts = []\n",
        "input_characters = set()\n",
        "target_characters = set()\n",
        "\n",
        "with open(data_path, 'r', encoding='utf-8') as f:\n",
        "    lines = f.read().split('\\n')\n",
        "    \n",
        "for line in lines[: min(num_samples, len(lines) - 1)]:\n",
        "    input_text, target_text, _ = line.split('\\t')\n",
        "    target_text = '\\t' + target_text + '\\n'\n",
        "    input_texts.append(input_text)\n",
        "    target_texts.append(target_text)\n",
        "    for char in input_text:\n",
        "        if char not in input_characters:\n",
        "            input_characters.add(char)\n",
        "    for char in target_text:\n",
        "        if char not in target_characters:\n",
        "            target_characters.add(char)\n",
        "\n",
        "input_characters = sorted(list(input_characters))\n",
        "target_characters = sorted(list(target_characters))\n",
        "num_encoder_tokens = len(input_characters)\n",
        "num_decoder_tokens = len(target_characters)\n",
        "max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
        "max_decoder_seq_length = max([len(txt) for txt in target_texts])"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5uuuX2ap_VOl"
      },
      "source": [
        "input_token_index = dict(\n",
        "    [(char, i) for i, char in enumerate(input_characters)])\n",
        "target_token_index = dict(\n",
        "    [(char, i) for i, char in enumerate(target_characters)])"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1heIqvfM_VOp"
      },
      "source": [
        "encoder_input_data = np.zeros(\n",
        "    (len(input_texts), max_encoder_seq_length, num_encoder_tokens),\n",
        "    dtype='float32')\n",
        "decoder_input_data = np.zeros(\n",
        "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
        "    dtype='float32')\n",
        "decoder_target_data = np.zeros(\n",
        "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
        "    dtype='float32')"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mU3yCc8f_VOs"
      },
      "source": [
        "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
        "    for t, char in enumerate(input_text):\n",
        "        encoder_input_data[i, t, input_token_index[char]] = 1.\n",
        "    encoder_input_data[i, t + 1:, input_token_index[' ']] = 1.\n",
        "    for t, char in enumerate(target_text):\n",
        "        decoder_input_data[i, t, target_token_index[char]] = 1.\n",
        "        if t > 0:\n",
        "            decoder_target_data[i, t - 1, target_token_index[char]] = 1.\n",
        "    decoder_input_data[i, t + 1:, target_token_index[' ']] = 1.\n",
        "    decoder_target_data[i, t:, target_token_index[' ']] = 1."
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQ1GBYkkUDDu",
        "outputId": "efdd42f9-8630-4afd-f600-c0b263a55902",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "decoder_input_data[0]"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 1., ..., 0., 0., 0.],\n",
              "       [0., 0., 1., ..., 0., 0., 0.],\n",
              "       [0., 0., 1., ..., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sXURokW9_VOw",
        "outputId": "f191b62f-024c-447b-c255-206dd91e0bbe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
        "encoder = LSTM(latent_dim, return_state=True)\n",
        "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
        "encoder_states = [state_h, state_c]\n",
        "\n",
        "decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_inputs,\n",
        "                                     initial_state=encoder_states)\n",
        "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          validation_split=0.2)\n",
        "\n",
        "encoder_model = Model(encoder_inputs, encoder_states)\n",
        "\n",
        "decoder_state_input_h = Input(shape=(latent_dim,))\n",
        "decoder_state_input_c = Input(shape=(latent_dim,))\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "decoder_outputs, state_h, state_c = decoder_lstm(\n",
        "    decoder_inputs, initial_state=decoder_states_inputs)\n",
        "decoder_states = [state_h, state_c]\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "decoder_model = Model(\n",
        "    [decoder_inputs] + decoder_states_inputs,\n",
        "    [decoder_outputs] + decoder_states)\n",
        "\n",
        "reverse_input_char_index = dict(\n",
        "    (i, char) for char, i in input_token_index.items())\n",
        "reverse_target_char_index = dict(\n",
        "    (i, char) for char, i in target_token_index.items())\n",
        "\n",
        "\n",
        "def decode_sequence(input_seq):\n",
        "    states_value = encoder_model.predict(input_seq)\n",
        "\n",
        "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
        "    target_seq[0, 0, target_token_index['\\t']] = 1.\n",
        "\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "    while not stop_condition:\n",
        "        output_tokens, h, c = decoder_model.predict(\n",
        "            [target_seq] + states_value)\n",
        "\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
        "        decoded_sentence += sampled_char\n",
        "\n",
        "        if (sampled_char == '\\n' or\n",
        "           len(decoded_sentence) > max_decoder_seq_length):\n",
        "            stop_condition = True\n",
        "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
        "        target_seq[0, 0, sampled_token_index] = 1.\n",
        "\n",
        "        states_value = [h, c]\n",
        "\n",
        "    return decoded_sentence\n",
        "\n",
        "\n",
        "for seq_index in range(100):\n",
        "    input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
        "    decoded_sentence = decode_sequence(input_seq)\n",
        "    print('-')\n",
        "    print('Input sentence:', input_texts[seq_index])\n",
        "    print('Decoded sentence:', decoded_sentence)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "125/125 [==============================] - 2s 18ms/step - loss: 1.1350 - accuracy: 0.7726 - val_loss: 0.9120 - val_accuracy: 0.7591\n",
            "Epoch 2/30\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.7358 - accuracy: 0.8021 - val_loss: 0.7767 - val_accuracy: 0.7945\n",
            "Epoch 3/30\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.6270 - accuracy: 0.8342 - val_loss: 0.6753 - val_accuracy: 0.8171\n",
            "Epoch 4/30\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.5545 - accuracy: 0.8467 - val_loss: 0.6195 - val_accuracy: 0.8251\n",
            "Epoch 5/30\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.5147 - accuracy: 0.8547 - val_loss: 0.5872 - val_accuracy: 0.8319\n",
            "Epoch 6/30\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.4893 - accuracy: 0.8605 - val_loss: 0.5624 - val_accuracy: 0.8375\n",
            "Epoch 7/30\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.4692 - accuracy: 0.8650 - val_loss: 0.5432 - val_accuracy: 0.8431\n",
            "Epoch 8/30\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.4534 - accuracy: 0.8688 - val_loss: 0.5245 - val_accuracy: 0.8478\n",
            "Epoch 9/30\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.4375 - accuracy: 0.8732 - val_loss: 0.5142 - val_accuracy: 0.8522\n",
            "Epoch 10/30\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.4235 - accuracy: 0.8767 - val_loss: 0.5034 - val_accuracy: 0.8538\n",
            "Epoch 11/30\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.4116 - accuracy: 0.8802 - val_loss: 0.4944 - val_accuracy: 0.8568\n",
            "Epoch 12/30\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.3993 - accuracy: 0.8837 - val_loss: 0.4893 - val_accuracy: 0.8583\n",
            "Epoch 13/30\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.3887 - accuracy: 0.8866 - val_loss: 0.4807 - val_accuracy: 0.8615\n",
            "Epoch 14/30\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.3783 - accuracy: 0.8897 - val_loss: 0.4749 - val_accuracy: 0.8636\n",
            "Epoch 15/30\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.3686 - accuracy: 0.8922 - val_loss: 0.4687 - val_accuracy: 0.8653\n",
            "Epoch 16/30\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.3587 - accuracy: 0.8953 - val_loss: 0.4635 - val_accuracy: 0.8666\n",
            "Epoch 17/30\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.3490 - accuracy: 0.8978 - val_loss: 0.4591 - val_accuracy: 0.8686\n",
            "Epoch 18/30\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.3404 - accuracy: 0.9004 - val_loss: 0.4534 - val_accuracy: 0.8712\n",
            "Epoch 19/30\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.3310 - accuracy: 0.9033 - val_loss: 0.4495 - val_accuracy: 0.8712\n",
            "Epoch 20/30\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.3229 - accuracy: 0.9055 - val_loss: 0.4521 - val_accuracy: 0.8712\n",
            "Epoch 21/30\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.3153 - accuracy: 0.9076 - val_loss: 0.4453 - val_accuracy: 0.8732\n",
            "Epoch 22/30\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.3080 - accuracy: 0.9097 - val_loss: 0.4426 - val_accuracy: 0.8739\n",
            "Epoch 23/30\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.2988 - accuracy: 0.9122 - val_loss: 0.4423 - val_accuracy: 0.8747\n",
            "Epoch 24/30\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.2904 - accuracy: 0.9149 - val_loss: 0.4425 - val_accuracy: 0.8750\n",
            "Epoch 25/30\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.2831 - accuracy: 0.9166 - val_loss: 0.4432 - val_accuracy: 0.8752\n",
            "Epoch 26/30\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.2754 - accuracy: 0.9191 - val_loss: 0.4407 - val_accuracy: 0.8762\n",
            "Epoch 27/30\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.2675 - accuracy: 0.9210 - val_loss: 0.4367 - val_accuracy: 0.8773\n",
            "Epoch 28/30\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.2595 - accuracy: 0.9234 - val_loss: 0.4410 - val_accuracy: 0.8776\n",
            "Epoch 29/30\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.2527 - accuracy: 0.9252 - val_loss: 0.4382 - val_accuracy: 0.8783\n",
            "Epoch 30/30\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.2451 - accuracy: 0.9275 - val_loss: 0.4424 - val_accuracy: 0.8780\n",
            "-\n",
            "Input sentence: Go.\n",
            "Decoded sentence: Продижда!\n",
            "\n",
            "-\n",
            "Input sentence: Go.\n",
            "Decoded sentence: Продижда!\n",
            "\n",
            "-\n",
            "Input sentence: Go.\n",
            "Decoded sentence: Продижда!\n",
            "\n",
            "-\n",
            "Input sentence: Hi.\n",
            "Decoded sentence: Здристь.\n",
            "\n",
            "-\n",
            "Input sentence: Hi.\n",
            "Decoded sentence: Здристь.\n",
            "\n",
            "-\n",
            "Input sentence: Hi.\n",
            "Decoded sentence: Здристь.\n",
            "\n",
            "-\n",
            "Input sentence: Hi.\n",
            "Decoded sentence: Здристь.\n",
            "\n",
            "-\n",
            "Input sentence: Hi.\n",
            "Decoded sentence: Здристь.\n",
            "\n",
            "-\n",
            "Input sentence: Run!\n",
            "Decoded sentence: Бегите!\n",
            "\n",
            "-\n",
            "Input sentence: Run!\n",
            "Decoded sentence: Бегите!\n",
            "\n",
            "-\n",
            "Input sentence: Run.\n",
            "Decoded sentence: Бегите!\n",
            "\n",
            "-\n",
            "Input sentence: Run.\n",
            "Decoded sentence: Бегите!\n",
            "\n",
            "-\n",
            "Input sentence: Who?\n",
            "Decoded sentence: Кто выи?\n",
            "\n",
            "-\n",
            "Input sentence: Wow!\n",
            "Decoded sentence: Каро!\n",
            "\n",
            "-\n",
            "Input sentence: Wow!\n",
            "Decoded sentence: Каро!\n",
            "\n",
            "-\n",
            "Input sentence: Wow!\n",
            "Decoded sentence: Каро!\n",
            "\n",
            "-\n",
            "Input sentence: Wow!\n",
            "Decoded sentence: Каро!\n",
            "\n",
            "-\n",
            "Input sentence: Wow!\n",
            "Decoded sentence: Каро!\n",
            "\n",
            "-\n",
            "Input sentence: Wow!\n",
            "Decoded sentence: Каро!\n",
            "\n",
            "-\n",
            "Input sentence: Fire!\n",
            "Decoded sentence: Приго!\n",
            "\n",
            "-\n",
            "Input sentence: Fire!\n",
            "Decoded sentence: Приго!\n",
            "\n",
            "-\n",
            "Input sentence: Help!\n",
            "Decoded sentence: Помогите!\n",
            "\n",
            "-\n",
            "Input sentence: Help!\n",
            "Decoded sentence: Помогите!\n",
            "\n",
            "-\n",
            "Input sentence: Help!\n",
            "Decoded sentence: Помогите!\n",
            "\n",
            "-\n",
            "Input sentence: Jump!\n",
            "Decoded sentence: Прыгай!\n",
            "\n",
            "-\n",
            "Input sentence: Jump!\n",
            "Decoded sentence: Прыгай!\n",
            "\n",
            "-\n",
            "Input sentence: Jump.\n",
            "Decoded sentence: Прыгайте!\n",
            "\n",
            "-\n",
            "Input sentence: Jump.\n",
            "Decoded sentence: Прыгайте!\n",
            "\n",
            "-\n",
            "Input sentence: Stop!\n",
            "Decoded sentence: Остановитесь!\n",
            "\n",
            "-\n",
            "Input sentence: Stop!\n",
            "Decoded sentence: Остановитесь!\n",
            "\n",
            "-\n",
            "Input sentence: Stop!\n",
            "Decoded sentence: Остановитесь!\n",
            "\n",
            "-\n",
            "Input sentence: Wait!\n",
            "Decoded sentence: Подожди!\n",
            "\n",
            "-\n",
            "Input sentence: Wait!\n",
            "Decoded sentence: Подожди!\n",
            "\n",
            "-\n",
            "Input sentence: Wait!\n",
            "Decoded sentence: Подожди!\n",
            "\n",
            "-\n",
            "Input sentence: Wait!\n",
            "Decoded sentence: Подожди!\n",
            "\n",
            "-\n",
            "Input sentence: Wait.\n",
            "Decoded sentence: Подождите.\n",
            "\n",
            "-\n",
            "Input sentence: Wait.\n",
            "Decoded sentence: Подождите.\n",
            "\n",
            "-\n",
            "Input sentence: Wait.\n",
            "Decoded sentence: Подождите.\n",
            "\n",
            "-\n",
            "Input sentence: Do it.\n",
            "Decoded sentence: Сделай это.\n",
            "\n",
            "-\n",
            "Input sentence: Go on.\n",
            "Decoded sentence: Поеделайте.\n",
            "\n",
            "-\n",
            "Input sentence: Go on.\n",
            "Decoded sentence: Поеделайте.\n",
            "\n",
            "-\n",
            "Input sentence: Hello!\n",
            "Decoded sentence: Привет!\n",
            "\n",
            "-\n",
            "Input sentence: Hello!\n",
            "Decoded sentence: Привет!\n",
            "\n",
            "-\n",
            "Input sentence: Hello!\n",
            "Decoded sentence: Привет!\n",
            "\n",
            "-\n",
            "Input sentence: Hello!\n",
            "Decoded sentence: Привет!\n",
            "\n",
            "-\n",
            "Input sentence: Hurry!\n",
            "Decoded sentence: Проспишите!\n",
            "\n",
            "-\n",
            "Input sentence: I ran.\n",
            "Decoded sentence: Я победил.\n",
            "\n",
            "-\n",
            "Input sentence: I ran.\n",
            "Decoded sentence: Я победил.\n",
            "\n",
            "-\n",
            "Input sentence: I ran.\n",
            "Decoded sentence: Я победил.\n",
            "\n",
            "-\n",
            "Input sentence: I ran.\n",
            "Decoded sentence: Я победил.\n",
            "\n",
            "-\n",
            "Input sentence: I see.\n",
            "Decoded sentence: Я поделал.\n",
            "\n",
            "-\n",
            "Input sentence: I see.\n",
            "Decoded sentence: Я поделал.\n",
            "\n",
            "-\n",
            "Input sentence: I see.\n",
            "Decoded sentence: Я поделал.\n",
            "\n",
            "-\n",
            "Input sentence: I try.\n",
            "Decoded sentence: Я помогла.\n",
            "\n",
            "-\n",
            "Input sentence: I try.\n",
            "Decoded sentence: Я помогла.\n",
            "\n",
            "-\n",
            "Input sentence: I try.\n",
            "Decoded sentence: Я помогла.\n",
            "\n",
            "-\n",
            "Input sentence: I won!\n",
            "Decoded sentence: Я победили!\n",
            "\n",
            "-\n",
            "Input sentence: I won!\n",
            "Decoded sentence: Я победили!\n",
            "\n",
            "-\n",
            "Input sentence: I won!\n",
            "Decoded sentence: Я победили!\n",
            "\n",
            "-\n",
            "Input sentence: I won!\n",
            "Decoded sentence: Я победили!\n",
            "\n",
            "-\n",
            "Input sentence: Oh no!\n",
            "Decoded sentence: А тень!\n",
            "\n",
            "-\n",
            "Input sentence: Relax.\n",
            "Decoded sentence: Подылжись.\n",
            "\n",
            "-\n",
            "Input sentence: Relax.\n",
            "Decoded sentence: Подылжись.\n",
            "\n",
            "-\n",
            "Input sentence: Relax.\n",
            "Decoded sentence: Подылжись.\n",
            "\n",
            "-\n",
            "Input sentence: Shoot!\n",
            "Decoded sentence: Стреши!\n",
            "\n",
            "-\n",
            "Input sentence: Smile.\n",
            "Decoded sentence: Улыбнитесь.\n",
            "\n",
            "-\n",
            "Input sentence: Smile.\n",
            "Decoded sentence: Улыбнитесь.\n",
            "\n",
            "-\n",
            "Input sentence: Smile.\n",
            "Decoded sentence: Улыбнитесь.\n",
            "\n",
            "-\n",
            "Input sentence: Smile.\n",
            "Decoded sentence: Улыбнитесь.\n",
            "\n",
            "-\n",
            "Input sentence: Smile.\n",
            "Decoded sentence: Улыбнитесь.\n",
            "\n",
            "-\n",
            "Input sentence: Smile.\n",
            "Decoded sentence: Улыбнитесь.\n",
            "\n",
            "-\n",
            "Input sentence: Attack!\n",
            "Decoded sentence: В нанава!\n",
            "\n",
            "-\n",
            "Input sentence: Cheers!\n",
            "Decoded sentence: Всебя ном!\n",
            "\n",
            "-\n",
            "Input sentence: Cheers!\n",
            "Decoded sentence: Всебя ном!\n",
            "\n",
            "-\n",
            "Input sentence: Cheers!\n",
            "Decoded sentence: Всебя ном!\n",
            "\n",
            "-\n",
            "Input sentence: Cheers!\n",
            "Decoded sentence: Всебя ном!\n",
            "\n",
            "-\n",
            "Input sentence: Cheers!\n",
            "Decoded sentence: Всебя ном!\n",
            "\n",
            "-\n",
            "Input sentence: Eat it.\n",
            "Decoded sentence: Поеше поди.\n",
            "\n",
            "-\n",
            "Input sentence: Eat up.\n",
            "Decoded sentence: Поедеме.\n",
            "\n",
            "-\n",
            "Input sentence: Freeze!\n",
            "Decoded sentence: Ниси не свидени.\n",
            "\n",
            "-\n",
            "Input sentence: Freeze!\n",
            "Decoded sentence: Ниси не свидени.\n",
            "\n",
            "-\n",
            "Input sentence: Freeze!\n",
            "Decoded sentence: Ниси не свидени.\n",
            "\n",
            "-\n",
            "Input sentence: Freeze!\n",
            "Decoded sentence: Ниси не свидени.\n",
            "\n",
            "-\n",
            "Input sentence: Get up.\n",
            "Decoded sentence: Вставай.\n",
            "\n",
            "-\n",
            "Input sentence: Get up.\n",
            "Decoded sentence: Вставай.\n",
            "\n",
            "-\n",
            "Input sentence: Get up.\n",
            "Decoded sentence: Вставай.\n",
            "\n",
            "-\n",
            "Input sentence: Go now.\n",
            "Decoded sentence: Идите её.\n",
            "\n",
            "-\n",
            "Input sentence: Go now.\n",
            "Decoded sentence: Идите её.\n",
            "\n",
            "-\n",
            "Input sentence: Go now.\n",
            "Decoded sentence: Идите её.\n",
            "\n",
            "-\n",
            "Input sentence: Go now.\n",
            "Decoded sentence: Идите её.\n",
            "\n",
            "-\n",
            "Input sentence: Go now.\n",
            "Decoded sentence: Идите её.\n",
            "\n",
            "-\n",
            "Input sentence: Go now.\n",
            "Decoded sentence: Идите её.\n",
            "\n",
            "-\n",
            "Input sentence: Go now.\n",
            "Decoded sentence: Идите её.\n",
            "\n",
            "-\n",
            "Input sentence: Go now.\n",
            "Decoded sentence: Идите её.\n",
            "\n",
            "-\n",
            "Input sentence: Go now.\n",
            "Decoded sentence: Идите её.\n",
            "\n",
            "-\n",
            "Input sentence: Got it!\n",
            "Decoded sentence: Полян!\n",
            "\n",
            "-\n",
            "Input sentence: Got it?\n",
            "Decoded sentence: Идите постаться.\n",
            "\n",
            "-\n",
            "Input sentence: Got it?\n",
            "Decoded sentence: Идите постаться.\n",
            "\n",
            "-\n",
            "Input sentence: Got it?\n",
            "Decoded sentence: Идите постаться.\n",
            "\n",
            "-\n",
            "Input sentence: Got it?\n",
            "Decoded sentence: Идите постаться.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3j5fTLo8_VO3"
      },
      "source": [
        "import re\n",
        "import tensorflow.compat.v1 as tf\n",
        "data_path = 'rus.txt'\n",
        "num_samples = 10000\n",
        "\n",
        "tf.enable_eager_execution()\n",
        "\n",
        "input_texts = []\n",
        "target_texts = []\n",
        "\n",
        "def preprocess_input_sentence(w):\n",
        "    w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
        "    w = re.sub(r'[\" \"]+', \" \", w)\n",
        "    w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n",
        "    w = w.strip()\n",
        "    w = '<start> ' + w + ' <end>'\n",
        "    return w\n",
        "def preprocess_target_sentence(w):\n",
        "    w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
        "    w = re.sub(r'[\" \"]+', \" \", w)\n",
        "    w = re.sub(r\"[^а-яА-Я?.!,¿]+\", \" \", w)\n",
        "    w = w.strip()\n",
        "    w = '<start> ' + w + ' <end>'\n",
        "    return w\n",
        "\n",
        "with open(data_path, 'r', encoding='utf-8') as f:\n",
        "    lines = f.read().split('\\n')\n",
        "\n",
        "for line in lines[: min(num_samples, len(lines) - 1)]:\n",
        "    input_text, target_text, _ = line.split('\\t')\n",
        "    target_text = '\\t' + target_text + '\\n'\n",
        "    input_texts.append(preprocess_input_sentence(input_text))\n",
        "    target_texts.append(preprocess_target_sentence(target_text))"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e3mdizSuVkxO",
        "outputId": "7493f36e-7355-4aea-9cfe-78e42494dce9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "input_texts[0]"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'<start> Go . <end>'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wbg_hVCtVmJI",
        "outputId": "3cadf733-de2c-4bef-92b5-90a45874eeaf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "target_texts[0]"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'<start> Марш ! <end>'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNtowXk9_VO6"
      },
      "source": [
        "def tokenize(lang):\n",
        "    lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
        "      filters='')\n",
        "    lang_tokenizer.fit_on_texts(lang)\n",
        "    tensor = lang_tokenizer.texts_to_sequences(lang)\n",
        "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,\n",
        "                                                         padding='post')\n",
        "    return tensor, lang_tokenizer"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XB-oaQWJ_VO9"
      },
      "source": [
        "input_tensor, inp_lang_tokenizer = tokenize(input_texts)\n",
        "target_tensor, targ_lang_tokenizer = tokenize(target_texts)"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nExJKLay_VPB"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lcpiBC11_VPE"
      },
      "source": [
        "BUFFER_SIZE = len(input_tensor_train)\n",
        "BATCH_SIZE = 64\n",
        "steps_per_epoch = len(input_tensor_train)//BATCH_SIZE\n",
        "embedding_dim = 256\n",
        "units = 1024\n",
        "\n",
        "vocab_inp_size = len(inp_lang_tokenizer.word_index)+1\n",
        "vocab_tar_size = len(targ_lang_tokenizer.word_index)+1\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y038Jd_L_VPH"
      },
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.batch_sz = batch_sz\n",
        "        self.enc_units = enc_units\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "        self.lstm = tf.keras.layers.GRU(self.enc_units,\n",
        "                                       return_sequences=True,\n",
        "                                       return_state=True)\n",
        "\n",
        "    def call(self, x, hidden):\n",
        "        x = self.embedding(x)\n",
        "        output, state = self.lstm(x, initial_state = hidden)\n",
        "        return output, state\n",
        "\n",
        "    def initialize_hidden_state(self):\n",
        "        return tf.zeros((self.batch_sz, self.enc_units))\n",
        "\n",
        "    \n",
        "class BahdanauAttention(tf.keras.layers.Layer):\n",
        "    def __init__(self, units):\n",
        "        super(BahdanauAttention, self).__init__()\n",
        "        self.W1 = tf.keras.layers.Dense(units)\n",
        "        self.W2 = tf.keras.layers.Dense(units)\n",
        "        self.V = tf.keras.layers.Dense(1)\n",
        "\n",
        "    def call(self, query, values):\n",
        "        query_with_time_axis = tf.expand_dims(query, 1)\n",
        "        score = self.V(tf.nn.tanh(\n",
        "            self.W1(query_with_time_axis) + self.W2(values)))\n",
        "\n",
        "        attention_weights = tf.nn.softmax(score, axis=1)\n",
        "        context_vector = attention_weights * values\n",
        "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "\n",
        "        return context_vector, attention_weights\n",
        "    \n",
        "    \n",
        "class Decoder(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.batch_sz = batch_sz\n",
        "        self.dec_units = dec_units\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "        self.lstm = tf.keras.layers.GRU(self.dec_units,\n",
        "                                       return_sequences=True,\n",
        "                                       return_state=True)\n",
        "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "        self.attention = BahdanauAttention(self.dec_units)\n",
        "\n",
        "    def call(self, x, hidden, enc_output):\n",
        "        context_vector, attention_weights = self.attention(hidden, enc_output)\n",
        "        x = self.embedding(x)\n",
        "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
        "        output, state = self.lstm(x)\n",
        "        output = tf.reshape(output, (-1, output.shape[2]))\n",
        "        x = self.fc(output)\n",
        "        return x, state, attention_weights"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYlCgLU8_VPL"
      },
      "source": [
        "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
        "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')\n",
        "\n",
        "def loss_function(real, pred):\n",
        "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "    loss_ = loss_object(real, pred)\n",
        "\n",
        "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "    loss_ *= mask\n",
        "\n",
        "    return tf.reduce_mean(loss_)"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33J1R8Xw_VPP"
      },
      "source": [
        "@tf.function\n",
        "def train_step(inp, targ, enc_hidden):\n",
        "    loss = 0\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
        "        dec_hidden = enc_hidden\n",
        "        dec_input = tf.expand_dims([targ_lang_tokenizer.word_index['<start>']] * BATCH_SIZE, 1)\n",
        "\n",
        "        for t in range(1, targ.shape[1]):\n",
        "            predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
        "            loss += loss_function(targ[:, t], predictions)\n",
        "            dec_input = tf.expand_dims(targ[:, t], 1)\n",
        "    \n",
        "    batch_loss = (loss / int(targ.shape[1]))\n",
        "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "    gradients = tape.gradient(loss, variables)\n",
        "    optimizer.apply_gradients(zip(gradients, variables))\n",
        "    return batch_loss"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9cS6ef9_VPS",
        "outputId": "cea57711-271a-4e28-f456-34cf5cd12108",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "EPOCHS = 10\n",
        "for epoch in range(EPOCHS):\n",
        "    enc_hidden = encoder.initialize_hidden_state()\n",
        "    total_loss = 0\n",
        "\n",
        "    for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
        "        batch_loss = train_step(inp, targ, enc_hidden)\n",
        "        total_loss += batch_loss\n",
        "    \n",
        "    print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                      total_loss / steps_per_epoch))"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Loss 1.6733\n",
            "Epoch 2 Loss 1.2465\n",
            "Epoch 3 Loss 1.0566\n",
            "Epoch 4 Loss 0.9081\n",
            "Epoch 5 Loss 0.7776\n",
            "Epoch 6 Loss 0.6575\n",
            "Epoch 7 Loss 0.5504\n",
            "Epoch 8 Loss 0.4593\n",
            "Epoch 9 Loss 0.3765\n",
            "Epoch 10 Loss 0.3154\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42FyZOA8_VPW"
      },
      "source": [
        "Некоторые украденные функции для оценки"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EYZ24gmt_VPW"
      },
      "source": [
        "max_length_targ, max_length_inp = target_tensor.shape[1], input_tensor.shape[1]\n",
        "\n",
        "def evaluate(sentence):\n",
        "    attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
        "    sentence = preprocess_input_sentence(sentence)\n",
        "    inputs = [inp_lang_tokenizer.word_index[i] for i in sentence.split(' ')]\n",
        "    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
        "                                                         maxlen=max_length_inp,\n",
        "                                                         padding='post')\n",
        "    inputs = tf.convert_to_tensor(inputs)\n",
        "    result = ''\n",
        "    hidden = [tf.zeros((1, units))]\n",
        "    enc_out, enc_hidden = encoder(inputs, hidden)\n",
        "    dec_hidden = enc_hidden\n",
        "    dec_input = tf.expand_dims([targ_lang_tokenizer.word_index['<start>']], 0)\n",
        "\n",
        "    for t in range(max_length_targ):\n",
        "        predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
        "                                                             dec_hidden,\n",
        "                                                             enc_out)\n",
        "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
        "        attention_plot[t] = attention_weights.numpy()\n",
        "\n",
        "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
        "\n",
        "        result += targ_lang_tokenizer.index_word[predicted_id] + ' '\n",
        "\n",
        "        if targ_lang_tokenizer.index_word[predicted_id] == '<end>':\n",
        "            return result, sentence, attention_plot\n",
        "        dec_input = tf.expand_dims([predicted_id], 0)\n",
        "    return result, sentence, attention_plot\n",
        "\n",
        "def plot_attention(attention, sentence, predicted_sentence):\n",
        "    fig = plt.figure(figsize=(10,10))\n",
        "    ax = fig.add_subplot(1, 1, 1)\n",
        "    ax.matshow(attention, cmap='viridis')\n",
        "    fontdict = {'fontsize': 14}\n",
        "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
        "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
        "    #ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "    #ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "    plt.show()\n",
        "    \n",
        "def translate(sentence):\n",
        "    result, sentence, attention_plot = evaluate(sentence)\n",
        "    print('Input: %s' % (sentence))\n",
        "    print('Predicted translation: {}'.format(result))\n",
        "    attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
        "    plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRirhOux_VPa",
        "outputId": "415f5c14-a0d8-41ac-9069-0301cb66d955",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 692
        }
      },
      "source": [
        "%pylab inline\n",
        "\n",
        "translate(u'she want sleep ')"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Populating the interactive namespace from numpy and matplotlib\n",
            "Input: <start> she want sleep <end>\n",
            "Predicted translation: она мертва . <end> \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5l9JgiohaiOR",
        "outputId": "28ea8507-584d-4926-f9ca-2273a8e028b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 675
        }
      },
      "source": [
        "translate(u'go here ')"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: <start> go here <end>\n",
            "Predicted translation: идите за вас ! <end> \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}
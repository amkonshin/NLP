{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "Lecture rnn.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qHECy8K7zhW9"
      },
      "source": [
        "Все три разновидности сети отработали неважно. GRU лишь немного превзошли RNN, на 0,5 %. В целом RNN не впечатлили, работали долго , результат неважный. Плюс ко всему , не получилось улучшить сети. Какие вообще есть методы улучшения сетей, за исключением изменений предобработки текста? Увеличение кол-ва нейронов увеличивает accuracy на 2 %, но сильно увеличивает время обучения и в кайо-то момент accuracy перестает расти. \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sN1Nv2Xx5ZPp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SmiafPALss_u",
        "outputId": "400be5f5-a5c8-400d-8add-7061604dd5a7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "stopwords = stopwords.words('english')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-YjwMPMGtToh",
        "outputId": "2a7842be-6775-4fdb-b344-aa6fe97474a3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip  install stop_words"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting stop_words\n",
            "  Downloading https://files.pythonhosted.org/packages/1c/cb/d58290804b7a4c5daa42abbbe2a93c477ae53e45541b1825e86f0dfaaf63/stop-words-2018.7.23.tar.gz\n",
            "Building wheels for collected packages: stop-words\n",
            "  Building wheel for stop-words (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for stop-words: filename=stop_words-2018.7.23-cp36-none-any.whl size=32916 sha256=6d4255c2f2a5018098766d6f637e46ca21252ab1c8236fa979c255c1975f00c1\n",
            "  Stored in directory: /root/.cache/pip/wheels/75/37/6a/2b295e03bd07290f0da95c3adb9a74ba95fbc333aa8b0c7c78\n",
            "Successfully built stop-words\n",
            "Installing collected packages: stop-words\n",
            "Successfully installed stop-words-2018.7.23\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nE4TrqGSrfw2"
      },
      "source": [
        "# попробуем запрограммировать простую рекурентную сеть. Возьмем датасет с прошлого занятия\n",
        "\n",
        "import pandas as pd\n",
        "from string import punctuation\n",
        "from stop_words import get_stop_words\n",
        "from pymorphy2 import MorphAnalyzer\n",
        "import re\n",
        "\n",
        "df_train = pd.read_csv(\"/train.csv\")\n",
        "df_test = pd.read_csv(\"/test.csv\")\n",
        "df_val = pd.read_csv(\"/val.csv\")\n",
        "\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3tAfq_6rfw7",
        "outputId": "815821a1-e4f0-4463-ea8b-2d4466a78710",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df_train.head()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>@alisachachka не уезжаааааааай. :(❤ я тоже не ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>RT @GalyginVadim: Ребята и девчата!\\nВсе в кин...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>RT @ARTEM_KLYUSHIN: Кто ненавидит пробки ретви...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>RT @epupybobv: Хочется котлету по-киевски. Зап...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>@KarineKurganova @Yess__Boss босапопа есбоса н...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id                                               text  class\n",
              "0   0  @alisachachka не уезжаааааааай. :(❤ я тоже не ...      0\n",
              "1   1  RT @GalyginVadim: Ребята и девчата!\\nВсе в кин...      1\n",
              "2   2  RT @ARTEM_KLYUSHIN: Кто ненавидит пробки ретви...      0\n",
              "3   3  RT @epupybobv: Хочется котлету по-киевски. Зап...      1\n",
              "4   4  @KarineKurganova @Yess__Boss босапопа есбоса н...      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7engA0fgrfxB"
      },
      "source": [
        "sw = set(get_stop_words(\"ru\"))\n",
        "exclude = set(punctuation)\n",
        "morpher = MorphAnalyzer()\n",
        "\n",
        "def preprocess_text(txt):\n",
        "    txt = str(txt)\n",
        "    txt = \"\".join(c for c in txt if c not in exclude)\n",
        "    txt = txt.lower()\n",
        "    txt = re.sub(\"\\sне\", \"не\", txt)\n",
        "    txt = [morpher.parse(word)[0].normal_form for word in txt.split() if word not in sw]\n",
        "    return \" \".join(txt)\n",
        "\n",
        "df_train['text'] = df_train['text'].apply(preprocess_text)\n",
        "df_val['text'] = df_val['text'].apply(preprocess_text)\n",
        "df_test['text'] = df_test['text'].apply(preprocess_text)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5T5Qlr8IrfxF"
      },
      "source": [
        "import numpy as np\n",
        "import keras\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, Dropout, Activation, Input, Embedding, Conv1D, GlobalMaxPool1D, SimpleRNN, LSTM, GRU, Masking\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.callbacks import TensorBoard \n",
        "from keras.objectives import categorical_crossentropy\n",
        "from keras.callbacks import EarlyStopping  "
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gf8ncKqqrfxJ"
      },
      "source": [
        "text_corpus_train = df_train['text'].values\n",
        "text_corpus_valid = df_val['text'].values\n",
        "text_corpus_test = df_test['text'].values"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XvfPRvqmrfxN"
      },
      "source": [
        "tokenizer = Tokenizer(num_words=None, \n",
        "                     filters='#$%&()*+-<=>@[\\\\]^_`{|}~\\t\\n',\n",
        "                     lower = False, split = ' ')\n",
        "tokenizer.fit_on_texts(text_corpus_train)\n",
        "\n",
        "sequences_train = tokenizer.texts_to_sequences(text_corpus_train)\n",
        "sequences_val = tokenizer.texts_to_sequences(text_corpus_valid)\n",
        "sequences_test = tokenizer.texts_to_sequences(text_corpus_test)\n",
        "\n",
        "word_count = len(tokenizer.index_word) + 1\n",
        "training_length = max([len(i.split()) for i in text_corpus_train])\n",
        "\n",
        "X_train = pad_sequences(sequences_train, maxlen=training_length)\n",
        "X_valid = pad_sequences(sequences_val, maxlen=training_length)\n",
        "\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adedQ-I0rfxR"
      },
      "source": [
        "y_train = df_train['class'].values\n",
        "y_val = df_val['class'].values"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOi0Gx71rfxW"
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(\n",
        "    Embedding(input_dim=word_count,\n",
        "              input_length=training_length,\n",
        "              output_dim=30,\n",
        "              trainable=True,\n",
        "              mask_zero=True))\n",
        "model.add(Masking(mask_value=0.0))\n",
        "\n",
        "model.add(SimpleRNN(256))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "csM8MBlorfxZ",
        "outputId": "c0396201-a0c1-4a92-cb73-5a61afaa632c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "early_stopping=EarlyStopping(monitor='val_loss')  \n",
        "\n",
        "\n",
        "history = model.fit(X_train, y_train,\n",
        "                    batch_size=512,\n",
        "                    epochs=10,\n",
        "                    verbose=1,\n",
        "                    validation_split=0.1,\n",
        "                    callbacks=[early_stopping])"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "319/319 [==============================] - 98s 308ms/step - loss: 0.5577 - accuracy: 0.6998 - val_loss: 0.4920 - val_accuracy: 0.7544\n",
            "Epoch 2/10\n",
            "319/319 [==============================] - 102s 319ms/step - loss: 0.2883 - accuracy: 0.8810 - val_loss: 0.5608 - val_accuracy: 0.7412\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8y-KRuXdrfxd",
        "outputId": "d1343222-4644-4b91-b1dd-2eb9cd26e78b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "score = model.evaluate(X_valid, y_val, batch_size=512, verbose=1)\n",
        "print('\\n')\n",
        "print('Test score:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "45/45 [==============================] - 3s 72ms/step - loss: 0.5841 - accuracy: 0.7360\n",
            "\n",
            "\n",
            "Test score: 0.5841225981712341\n",
            "Test accuracy: 0.7360137701034546\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j2E1s_MGrfxh",
        "outputId": "f43bb85b-6900-4a83-ffe6-061ea52ac0ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(\n",
        "    Embedding(input_dim=word_count,\n",
        "              input_length=training_length,\n",
        "              output_dim=30,\n",
        "              trainable=True,\n",
        "              mask_zero=True))\n",
        "model.add(Masking(mask_value=0.0))\n",
        "model.add(LSTM(64, recurrent_dropout=0.2))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "early_stopping=EarlyStopping(monitor='val_loss')  \n",
        "\n",
        "\n",
        "history = model.fit(X_train, y_train,\n",
        "                    batch_size=512,\n",
        "                    epochs=10,\n",
        "                    verbose=1,\n",
        "                    validation_split=0.1,\n",
        "                    callbacks=[early_stopping])"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "319/319 [==============================] - 75s 235ms/step - loss: 0.5517 - accuracy: 0.7101 - val_loss: 0.4956 - val_accuracy: 0.7541\n",
            "Epoch 2/10\n",
            "319/319 [==============================] - 75s 235ms/step - loss: 0.3251 - accuracy: 0.8651 - val_loss: 0.5269 - val_accuracy: 0.7510\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gg8AVIXarfxk",
        "outputId": "bd0e18c0-bbdc-444d-9717-a0201fc25711",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "score = model.evaluate(X_valid, y_val, batch_size=512, verbose=1)\n",
        "print('\\n')\n",
        "print('Test score:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "45/45 [==============================] - 1s 32ms/step - loss: 0.5776 - accuracy: 0.7351\n",
            "\n",
            "\n",
            "Test score: 0.5776057243347168\n",
            "Test accuracy: 0.7350879311561584\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEpW_tAlrfxo",
        "outputId": "9158621c-946e-4aaf-9b8b-88b545fb1622",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(\n",
        "    Embedding(input_dim=word_count,\n",
        "              input_length=training_length,\n",
        "              output_dim=30,\n",
        "              trainable=True,\n",
        "              mask_zero=True))\n",
        "model.add(Masking(mask_value=0.0))\n",
        "model.add(GRU(128, recurrent_dropout=0.2))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "early_stopping=EarlyStopping(monitor='val_loss')  \n",
        "\n",
        "\n",
        "history = model.fit(X_train, y_train,\n",
        "                    batch_size=512,\n",
        "                    epochs=10,\n",
        "                    verbose=1,\n",
        "                    validation_split=0.1,\n",
        "                    callbacks=[early_stopping])"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "319/319 [==============================] - 118s 371ms/step - loss: 0.5459 - accuracy: 0.7131 - val_loss: 0.4872 - val_accuracy: 0.7583\n",
            "Epoch 2/10\n",
            "319/319 [==============================] - 118s 370ms/step - loss: 0.3033 - accuracy: 0.8742 - val_loss: 0.5320 - val_accuracy: 0.7466\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SlbdmMyErfxs",
        "outputId": "043a3b6f-c1a2-494b-ab23-3415413786a5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "score = model.evaluate(X_valid, y_val, batch_size=512, verbose=1)\n",
        "print('\\n')\n",
        "print('Test score:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "45/45 [==============================] - 3s 66ms/step - loss: 0.5845 - accuracy: 0.7357\n",
            "\n",
            "\n",
            "Test score: 0.5844850540161133\n",
            "Test accuracy: 0.7356610894203186\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}